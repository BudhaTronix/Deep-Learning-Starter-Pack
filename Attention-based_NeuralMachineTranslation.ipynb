{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B2Th_Q771WDP"
   },
   "source": [
    "# **TASK 5 : Attention-based NMT**\n",
    "\n",
    "This tasks aims to give you a better practical understanding of Attention mechanisms as they fell short in the Assignments.\n",
    "In this task, you will implement a simple NMT with attention for a language pair of your choice.\n",
    "We will follow the corresponding TF Tutorial on NMT.\n",
    "\n",
    "Please do not use the exemplary English-Spanish example to reduce temptation of simply copying the tutorial.\n",
    "You can find data sets here. I recommend to pick a language pair where you understand both languages.\n",
    "This makes it easier (and more fun) for you to evaluate the results.\n",
    "\n",
    "Recommendation: Start with a small number of training examples. Use one of the training examples to evaluate whether training worked properly.\n",
    "Only switch to the complete data set if you’re sure that your code works, because training is quite slow.\n",
    "Note that many words are out-of-vocabulary (OOV) when using few examples.\n",
    "\n",
    "Tasks:\n",
    "\n",
    "Follow the tutorial and train the model on your chosen language pair (using Bahdanau attention).\n",
    "You might need to adapt the preprocessing depending on the language.\n",
    "Implement other attention mechanisms and train models with them\n",
    "dot product attention \n",
    "Luong’s multiplicative attention \n",
    "Hint: Storing the models is important, so you don’t need to retrain them all the time.\n",
    "Also take care to not overwrite model checkpoints when switching from additive to multiplicative attention.\n",
    "\n",
    "Compare the attention weight plots for some examples between the attention mechanisms.\n",
    "I recommend to add ,clim=[0,1] when creating the plot in ax.matshow(attention, cmap='viridis') so the colors correspond to the same attention values in different plots.\n",
    "Note that the tutorial crops off the padding in the attention plot although the decoder can attend to those too.\n",
    "Do you see qualitative differences in the attention weights between different attention mechanisms?\n",
    "Do you think that the model attends to the correct tokens in the input language? (if you understand both languages)\n",
    "\n",
    "Here are a few questions for you to check how well you understood the tutorial.\n",
    "Please answer them (briefly) in your solution!\n",
    "\n",
    "Which parts of the sentence are used as a token? Each character, each word, or are some words split up?\n",
    "Do the same tokens in different language have the same ID?\n",
    "e.g. Would the same token index map to the German word die and to the English word die?\n",
    "What is the relation between the encoder output and the encoder hidden state which is used to initialize the decoder hidden state?\n",
    "(for the architecture used in the tutorial)\n",
    "Is the decoder attending to all previous positions, including the previous decoder predictions?\n",
    "Does the Encoder output change in different decoding steps?\n",
    "Does the context vector change in different decoding steps?\n",
    "The decoder uses teacher forcing. Does this mean the time steps can be computed in parallel?\n",
    "Why is a mask applied to the loss function?\n",
    "Bonus1: Can you prevent the attention mechanism from attending to padded positions in the sequence?\n",
    "\n",
    "Bonus2: The tutorial suggests to restore checkpoints for loading a model.\n",
    "This is inconvenient, because you first need to process the data, build the whole architecture and then initialize it from the checkpoint.\n",
    "It would be much nicer to simply load a model and run translations with it. Can you find a way to achieve this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2686,
     "status": "ok",
     "timestamp": 1600201990313,
     "user": {
      "displayName": "Budhaditya Mukhopadhyay",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjhEyQYtB08E19TTD1GE25cdVV6J1caJTjg47JiCTg=s64",
      "userId": "05521750824977221992"
     },
     "user_tz": -120
    },
    "id": "-IglC_XE1n59"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 713,
     "status": "ok",
     "timestamp": 1600201990927,
     "user": {
      "displayName": "Budhaditya Mukhopadhyay",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjhEyQYtB08E19TTD1GE25cdVV6J1caJTjg47JiCTg=s64",
      "userId": "05521750824977221992"
     },
     "user_tz": -120
    },
    "id": "cscrzLz91op9",
    "outputId": "ee581cb0-de5e-4d92-ab61-8ab7e2784d3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "path_to_zip = '/content/drive/My Drive/Colab Notebooks/IDL_FinalSubmission/'\n",
    "path_to_file = os.path.dirname(path_to_zip)+\"/deu.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 675,
     "status": "ok",
     "timestamp": 1600201994681,
     "user": {
      "displayName": "Budhaditya Mukhopadhyay",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjhEyQYtB08E19TTD1GE25cdVV6J1caJTjg47JiCTg=s64",
      "userId": "05521750824977221992"
     },
     "user_tz": -120
    },
    "id": "W6RLNfY05yxS",
    "outputId": "2840ae87-9562-46a0-bd70-735d7622eb18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/Colab Notebooks/IDL_FinalSubmission/deu.txt\n"
     ]
    }
   ],
   "source": [
    "print(path_to_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 920,
     "status": "ok",
     "timestamp": 1600201997086,
     "user": {
      "displayName": "Budhaditya Mukhopadhyay",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjhEyQYtB08E19TTD1GE25cdVV6J1caJTjg47JiCTg=s64",
      "userId": "05521750824977221992"
     },
     "user_tz": -120
    },
    "id": "frnD81U4FAhP"
   },
   "outputs": [],
   "source": [
    "# Converts the unicode file to ascii\n",
    "def unicode_to_ascii(s):\n",
    "  return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "      if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "\n",
    "def preprocess_sentence(w):\n",
    "  w = unicode_to_ascii(w.lower().strip())\n",
    "\n",
    "  # creating a space between a word and the punctuation following it\n",
    "  # eg: \"he is a boy.\" => \"he is a boy .\"\n",
    "  # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
    "  w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
    "  w = re.sub(r'[\" \"]+', \" \", w)\n",
    "\n",
    "  # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
    "  w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
    "\n",
    "  w = w.strip()\n",
    "\n",
    "  # adding a start and an end token to the sentence\n",
    "  # so that the model know when to start and stop predicting.\n",
    "  w = '<start> ' + w + ' <end>'\n",
    "  return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 634,
     "status": "ok",
     "timestamp": 1600201998889,
     "user": {
      "displayName": "Budhaditya Mukhopadhyay",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjhEyQYtB08E19TTD1GE25cdVV6J1caJTjg47JiCTg=s64",
      "userId": "05521750824977221992"
     },
     "user_tz": -120
    },
    "id": "X3SvMptkG8K3",
    "outputId": "f49f8d77-055c-4d75-ad2f-10d2acb7ef29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> may i borrow this book ? <end>\n",
      "b'<start> darf ich dieses buch ausleihen ? <end>'\n"
     ]
    }
   ],
   "source": [
    "en_sentence = u\"May I borrow this book?\"\n",
    "de_sentence = u\"Darf ich dieses Buch ausleihen?\"\n",
    "print(preprocess_sentence(en_sentence))\n",
    "print(preprocess_sentence(de_sentence).encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 829,
     "status": "ok",
     "timestamp": 1600202002536,
     "user": {
      "displayName": "Budhaditya Mukhopadhyay",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjhEyQYtB08E19TTD1GE25cdVV6J1caJTjg47JiCTg=s64",
      "userId": "05521750824977221992"
     },
     "user_tz": -120
    },
    "id": "t5XEf_v-HomV"
   },
   "outputs": [],
   "source": [
    "# 1. Remove the accents\n",
    "# 2. Clean the sentences\n",
    "# 3. Return word pairs in the format: [ENGLISH, SPANISH]\n",
    "def create_dataset(path, num_examples):\n",
    "  lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
    "\n",
    "  word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')]  for l in lines[:num_examples]]\n",
    "\n",
    "  return zip(*word_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11222,
     "status": "ok",
     "timestamp": 1600202015969,
     "user": {
      "displayName": "Budhaditya Mukhopadhyay",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjhEyQYtB08E19TTD1GE25cdVV6J1caJTjg47JiCTg=s64",
      "userId": "05521750824977221992"
     },
     "user_tz": -120
    },
    "id": "3g3otE4SIFTB",
    "outputId": "53ec4271-dda4-4078-f164-4a5280eb4cf6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> doubtless there exists in this world precisely the right woman for any given man to marry and vice versa but when you consider that a human being has the opportunity of being acquainted with only a few hundred people , and out of the few hundred that there are but a dozen or less whom he knows intimately , and out of the dozen , one or two friends at most , it will easily be seen , when we remember the number of millions who inhabit this world , that probably , since the earth was created , the right man has never yet met the right woman . <end>\n",
      "<start> ohne zweifel findet sich auf dieser welt zu jedem mann genau die richtige ehefrau und umgekehrt wenn man jedoch in betracht zieht , dass ein mensch nur gelegenheit hat , mit ein paar hundert anderen bekannt zu sein , von denen ihm nur ein dutzend oder weniger nahesteht , darunter hochstens ein oder zwei freunde , dann erahnt man eingedenk der millionen einwohner dieser welt leicht , dass seit erschaffung ebenderselben wohl noch nie der richtige mann der richtigen frau begegnet ist . <end>\n"
     ]
    }
   ],
   "source": [
    "en, de = create_dataset(path_to_file, None)\n",
    "print(en[-1])\n",
    "print(de[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 638,
     "status": "ok",
     "timestamp": 1600202020331,
     "user": {
      "displayName": "Budhaditya Mukhopadhyay",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjhEyQYtB08E19TTD1GE25cdVV6J1caJTjg47JiCTg=s64",
      "userId": "05521750824977221992"
     },
     "user_tz": -120
    },
    "id": "mjIvwHbHIIDX"
   },
   "outputs": [],
   "source": [
    "def tokenize(lang):\n",
    "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "      filters='')\n",
    "  lang_tokenizer.fit_on_texts(lang)\n",
    "\n",
    "  tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    "\n",
    "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
    "                                                         padding='post')\n",
    "\n",
    "  return tensor, lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 631,
     "status": "ok",
     "timestamp": 1600202026463,
     "user": {
      "displayName": "Budhaditya Mukhopadhyay",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjhEyQYtB08E19TTD1GE25cdVV6J1caJTjg47JiCTg=s64",
      "userId": "05521750824977221992"
     },
     "user_tz": -120
    },
    "id": "dahFegcyOgA-"
   },
   "outputs": [],
   "source": [
    "def load_dataset(path, num_examples=None):\n",
    "  # creating cleaned input, output pairs\n",
    "  targ_lang, inp_lang = create_dataset(path, num_examples)\n",
    "\n",
    "  input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
    "  target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
    "\n",
    "  return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11077,
     "status": "ok",
     "timestamp": 1600202039115,
     "user": {
      "displayName": "Budhaditya Mukhopadhyay",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjhEyQYtB08E19TTD1GE25cdVV6J1caJTjg47JiCTg=s64",
      "userId": "05521750824977221992"
     },
     "user_tz": -120
    },
    "id": "dr3V97qaQlni"
   },
   "outputs": [],
   "source": [
    "# Try experimenting with the size of that dataset\n",
    "num_examples = 150000\n",
    "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(path_to_file, num_examples)\n",
    "\n",
    "# Calculate max_length of the target tensors\n",
    "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9403,
     "status": "ok",
     "timestamp": 1600202039117,
     "user": {
      "displayName": "Budhaditya Mukhopadhyay",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjhEyQYtB08E19TTD1GE25cdVV6J1caJTjg47JiCTg=s64",
      "userId": "05521750824977221992"
     },
     "user_tz": -120
    },
    "id": "yZ38YuTFQoJV",
    "outputId": "7be1cc6f-99de-4829-c08b-06a276288071"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120000 120000 30000 30000\n"
     ]
    }
   ],
   "source": [
    "# Creating training and validation sets using an 80-20 split\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
    "\n",
    "# Show length\n",
    "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6256,
     "status": "ok",
     "timestamp": 1600202039118,
     "user": {
      "displayName": "Budhaditya Mukhopadhyay",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjhEyQYtB08E19TTD1GE25cdVV6J1caJTjg47JiCTg=s64",
      "userId": "05521750824977221992"
     },
     "user_tz": -120
    },
    "id": "LijMqyoJQpyu"
   },
   "outputs": [],
   "source": [
    "def convert(lang, tensor):\n",
    "  for t in tensor:\n",
    "    if t!=0:\n",
    "      print (\"%d ----> %s\" % (t, lang.index_word[t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4605,
     "status": "ok",
     "timestamp": 1600202039118,
     "user": {
      "displayName": "Budhaditya Mukhopadhyay",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjhEyQYtB08E19TTD1GE25cdVV6J1caJTjg47JiCTg=s64",
      "userId": "05521750824977221992"
     },
     "user_tz": -120
    },
    "id": "G-7T3lxpQsdu",
    "outputId": "84f4dab0-8dee-4715-e027-54953c2e37c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Language; index to word mapping\n",
      "1 ----> <start>\n",
      "20 ----> wir\n",
      "37 ----> haben\n",
      "753 ----> thomas\n",
      "9 ----> nicht\n",
      "1167 ----> getotet\n",
      "3 ----> .\n",
      "2 ----> <end>\n",
      "\n",
      "Target Language; index to word mapping\n",
      "1 ----> <start>\n",
      "21 ----> we\n",
      "58 ----> didn\n",
      "11 ----> t\n",
      "530 ----> kill\n",
      "5 ----> tom\n",
      "3 ----> .\n",
      "2 ----> <end>\n"
     ]
    }
   ],
   "source": [
    "print (\"Input Language; index to word mapping\")\n",
    "convert(inp_lang, input_tensor_train[2460])\n",
    "print ()\n",
    "print (\"Target Language; index to word mapping\")\n",
    "convert(targ_lang, target_tensor_train[2460])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6260,
     "status": "ok",
     "timestamp": 1600202045393,
     "user": {
      "displayName": "Budhaditya Mukhopadhyay",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjhEyQYtB08E19TTD1GE25cdVV6J1caJTjg47JiCTg=s64",
      "userId": "05521750824977221992"
     },
     "user_tz": -120
    },
    "id": "KXzVX40SQwZz"
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "vocab_inp_size = len(inp_lang.word_index)+1\n",
    "vocab_tar_size = len(targ_lang.word_index)+1\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 887,
     "status": "ok",
     "timestamp": 1600202047326,
     "user": {
      "displayName": "Budhaditya Mukhopadhyay",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjhEyQYtB08E19TTD1GE25cdVV6J1caJTjg47JiCTg=s64",
      "userId": "05521750824977221992"
     },
     "user_tz": -120
    },
    "id": "4PF5psgwQy7k",
    "outputId": "6559e663-fe59-4823-8043-858df87602dc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 24]), TensorShape([64, 14]))"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input_batch, example_target_batch = next(iter(dataset))\n",
    "example_input_batch.shape, example_target_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 669,
     "status": "ok",
     "timestamp": 1600202051328,
     "user": {
      "displayName": "Budhaditya Mukhopadhyay",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjhEyQYtB08E19TTD1GE25cdVV6J1caJTjg47JiCTg=s64",
      "userId": "05521750824977221992"
     },
     "user_tz": -120
    },
    "id": "i-cGWT00Qziv"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "    super(Encoder, self).__init__()\n",
    "    self.batch_sz = batch_sz\n",
    "    self.enc_units = enc_units\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "\n",
    "  def call(self, x, hidden):\n",
    "    x = self.embedding(x)\n",
    "    output, state = self.gru(x, initial_state = hidden)\n",
    "    return output, state\n",
    "\n",
    "  def initialize_hidden_state(self):\n",
    "    return tf.zeros((self.batch_sz, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5666,
     "status": "ok",
     "timestamp": 1600202068545,
     "user": {
      "displayName": "Budhaditya Mukhopadhyay",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjhEyQYtB08E19TTD1GE25cdVV6J1caJTjg47JiCTg=s64",
      "userId": "05521750824977221992"
     },
     "user_tz": -120
    },
    "id": "3UASnR4jQ4GC",
    "outputId": "0b7229d9-001e-458e-9731-37cca0e239f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: (batch size, sequence length, units) (64, 24, 1024)\n",
      "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "# sample input\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
    "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m_WQtAiuIM9n"
   },
   "source": [
    "## Bahdanau Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 31627,
     "status": "ok",
     "timestamp": 1600196894881,
     "user": {
      "displayName": "Budhaditya Mukhopadhyay",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjhEyQYtB08E19TTD1GE25cdVV6J1caJTjg47JiCTg=s64",
      "userId": "05521750824977221992"
     },
     "user_tz": -120
    },
    "id": "4jA_Ze2cRfLD"
   },
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self, units):\n",
    "    super(BahdanauAttention, self).__init__()\n",
    "    self.W1 = tf.keras.layers.Dense(units)\n",
    "    self.W2 = tf.keras.layers.Dense(units)\n",
    "    self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "  def call(self, query, values):\n",
    "    # query hidden state shape == (batch_size, hidden size)\n",
    "    # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "    # values shape == (batch_size, max_len, hidden size)\n",
    "    # we are doing this to broadcast addition along the time axis to calculate the score\n",
    "    query_with_time_axis = tf.expand_dims(query, 1)\n",
    "    \n",
    "    # score shape == (batch_size, max_length, 1)\n",
    "    # we get 1 at the last axis because we are applying score to self.V\n",
    "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
    "    score = self.V(tf.nn.tanh(\n",
    "        self.W1(query_with_time_axis) + self.W2(values)))\n",
    "\n",
    "    # attention_weights shape == (batch_size, max_length, 1)\n",
    "    attention_weights = tf.nn.softmax(score, axis=1)\n",
    "    print(attention_weights.shape)\n",
    "    # context_vector shape after sum == (batch_size, hidden_size)\n",
    "    context_vector = attention_weights * values\n",
    "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "    return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 32975,
     "status": "ok",
     "timestamp": 1600196896242,
     "user": {
      "displayName": "Budhaditya Mukhopadhyay",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjhEyQYtB08E19TTD1GE25cdVV6J1caJTjg47JiCTg=s64",
      "userId": "05521750824977221992"
     },
     "user_tz": -120
    },
    "id": "tGAH88ckRhTf",
    "outputId": "5e56bf59-1726-449a-f8b5-1e30fcdc1210"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 24, 1)\n",
      "Attention result shape: (batch size, units) (64, 1024)\n",
      "Attention weights shape: (batch_size, sequence_length, 1) (64, 24, 1)\n"
     ]
    }
   ],
   "source": [
    "attention_layer = BahdanauAttention(1024)\n",
    "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
    "\n",
    "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
    "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 32973,
     "status": "ok",
     "timestamp": 1600196896243,
     "user": {
      "displayName": "Budhaditya Mukhopadhyay",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjhEyQYtB08E19TTD1GE25cdVV6J1caJTjg47JiCTg=s64",
      "userId": "05521750824977221992"
     },
     "user_tz": -120
    },
    "id": "JLJv2wd9RjqP"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "    super(Decoder, self).__init__()\n",
    "    self.batch_sz = batch_sz\n",
    "    self.dec_units = dec_units\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    # used for attention\n",
    "    self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "  def call(self, x, hidden, enc_output):\n",
    "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
    "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "\n",
    "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "    x = self.embedding(x)\n",
    "\n",
    "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "    # passing the concatenated vector to the GRU\n",
    "    output, state = self.gru(x)\n",
    "\n",
    "    # output shape == (batch_size * 1, hidden_size)\n",
    "    output = tf.reshape(output, (-1, output.shape[2]))\n",
    "\n",
    "    # output shape == (batch_size, vocab)\n",
    "    x = self.fc(output)\n",
    "\n",
    "    return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 32959,
     "status": "ok",
     "timestamp": 1600196896244,
     "user": {
      "displayName": "Budhaditya Mukhopadhyay",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjhEyQYtB08E19TTD1GE25cdVV6J1caJTjg47JiCTg=s64",
      "userId": "05521750824977221992"
     },
     "user_tz": -120
    },
    "id": "hyDFhg1WRmGM",
    "outputId": "cbde2296-bcbc-4925-e7eb-9cb1200e6a2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 24, 1)\n",
      "Decoder output shape: (batch_size, vocab size) (64, 11205)\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
    "                                      sample_hidden, sample_output)\n",
    "\n",
    "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 32956,
     "status": "ok",
     "timestamp": 1600196896244,
     "user": {
      "displayName": "Budhaditya Mukhopadhyay",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjhEyQYtB08E19TTD1GE25cdVV6J1caJTjg47JiCTg=s64",
      "userId": "05521750824977221992"
     },
     "user_tz": -120
    },
    "id": "orf4ooprRoU4"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  loss_ = loss_object(real, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "  loss_ *= mask\n",
    "\n",
    "  return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 32955,
     "status": "ok",
     "timestamp": 1600196896245,
     "user": {
      "displayName": "Budhaditya Mukhopadhyay",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjhEyQYtB08E19TTD1GE25cdVV6J1caJTjg47JiCTg=s64",
      "userId": "05521750824977221992"
     },
     "user_tz": -120
    },
    "id": "FM7VVj5jRo7l"
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints_Bahdanau'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 32952,
     "status": "ok",
     "timestamp": 1600196896245,
     "user": {
      "displayName": "Budhaditya Mukhopadhyay",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjhEyQYtB08E19TTD1GE25cdVV6J1caJTjg47JiCTg=s64",
      "userId": "05521750824977221992"
     },
     "user_tz": -120
    },
    "id": "FZsgxp0URv0Q"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "  loss = 0\n",
    "\n",
    "  with tf.GradientTape() as tape:\n",
    "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "\n",
    "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "\n",
    "    # Teacher forcing - feeding the target as the next input\n",
    "    for t in range(1, targ.shape[1]):\n",
    "      # passing enc_output to the decoder\n",
    "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "\n",
    "      loss += loss_function(targ[:, t], predictions)\n",
    "\n",
    "      # using teacher forcing\n",
    "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "  batch_loss = (loss / int(targ.shape[1]))\n",
    "\n",
    "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "  gradients = tape.gradient(loss, variables)\n",
    "\n",
    "  optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "  return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2461408,
     "status": "ok",
     "timestamp": 1600199324713,
     "user": {
      "displayName": "Budhaditya Mukhopadhyay",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjhEyQYtB08E19TTD1GE25cdVV6J1caJTjg47JiCTg=s64",
      "userId": "05521750824977221992"
     },
     "user_tz": -120
    },
    "id": "xg-9kmV5Rzvy",
    "outputId": "16c34ab2-504d-41a8-a1a8-692d6b88fd2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 24, 1)\n",
      "(64, 24, 1)\n",
      "(64, 24, 1)\n",
      "(64, 24, 1)\n",
      "(64, 24, 1)\n",
      "(64, 24, 1)\n",
      "(64, 24, 1)\n",
      "(64, 24, 1)\n",
      "(64, 24, 1)\n",
      "(64, 24, 1)\n",
      "(64, 24, 1)\n",
      "(64, 24, 1)\n",
      "(64, 24, 1)\n",
      "(64, 24, 1)\n",
      "(64, 24, 1)\n",
      "(64, 24, 1)\n",
      "(64, 24, 1)\n",
      "(64, 24, 1)\n",
      "(64, 24, 1)\n",
      "(64, 24, 1)\n",
      "(64, 24, 1)\n",
      "(64, 24, 1)\n",
      "(64, 24, 1)\n",
      "(64, 24, 1)\n",
      "(64, 24, 1)\n",
      "(64, 24, 1)\n",
      "Epoch 1 Batch 0 Loss 4.9845\n",
      "Epoch 1 Batch 100 Loss 2.4267\n",
      "Epoch 1 Batch 200 Loss 2.3312\n",
      "Epoch 1 Batch 300 Loss 2.0875\n",
      "Epoch 1 Batch 400 Loss 1.9651\n",
      "Epoch 1 Batch 500 Loss 1.9477\n",
      "Epoch 1 Batch 600 Loss 1.8869\n",
      "Epoch 1 Batch 700 Loss 1.7315\n",
      "Epoch 1 Batch 800 Loss 1.7050\n",
      "Epoch 1 Batch 900 Loss 1.6099\n",
      "Epoch 1 Batch 1000 Loss 1.5492\n",
      "Epoch 1 Batch 1100 Loss 1.5104\n",
      "Epoch 1 Batch 1200 Loss 1.4790\n",
      "Epoch 1 Batch 1300 Loss 1.5133\n",
      "Epoch 1 Batch 1400 Loss 1.3258\n",
      "Epoch 1 Batch 1500 Loss 1.2591\n",
      "Epoch 1 Batch 1600 Loss 1.4278\n",
      "Epoch 1 Batch 1700 Loss 1.3065\n",
      "Epoch 1 Batch 1800 Loss 1.1346\n",
      "Epoch 1 Loss 1.6845\n",
      "Time taken for 1 epoch 254.39041805267334 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 1.1075\n",
      "Epoch 2 Batch 100 Loss 1.0618\n",
      "Epoch 2 Batch 200 Loss 0.9924\n",
      "Epoch 2 Batch 300 Loss 0.9055\n",
      "Epoch 2 Batch 400 Loss 0.8806\n",
      "Epoch 2 Batch 500 Loss 0.7591\n",
      "Epoch 2 Batch 600 Loss 0.9005\n",
      "Epoch 2 Batch 700 Loss 0.8178\n",
      "Epoch 2 Batch 800 Loss 0.7540\n",
      "Epoch 2 Batch 900 Loss 0.8036\n",
      "Epoch 2 Batch 1000 Loss 0.6651\n",
      "Epoch 2 Batch 1100 Loss 0.7272\n",
      "Epoch 2 Batch 1200 Loss 0.7994\n",
      "Epoch 2 Batch 1300 Loss 0.6245\n",
      "Epoch 2 Batch 1400 Loss 0.7021\n",
      "Epoch 2 Batch 1500 Loss 0.6749\n",
      "Epoch 2 Batch 1600 Loss 0.6449\n",
      "Epoch 2 Batch 1700 Loss 0.6648\n",
      "Epoch 2 Batch 1800 Loss 0.6509\n",
      "Epoch 2 Loss 0.7916\n",
      "Time taken for 1 epoch 242.51753783226013 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 0.4893\n",
      "Epoch 3 Batch 100 Loss 0.4842\n",
      "Epoch 3 Batch 200 Loss 0.4530\n",
      "Epoch 3 Batch 300 Loss 0.5756\n",
      "Epoch 3 Batch 400 Loss 0.5519\n",
      "Epoch 3 Batch 500 Loss 0.5694\n",
      "Epoch 3 Batch 600 Loss 0.3808\n",
      "Epoch 3 Batch 700 Loss 0.4972\n",
      "Epoch 3 Batch 800 Loss 0.4437\n",
      "Epoch 3 Batch 900 Loss 0.5413\n",
      "Epoch 3 Batch 1000 Loss 0.4018\n",
      "Epoch 3 Batch 1100 Loss 0.4960\n",
      "Epoch 3 Batch 1200 Loss 0.4133\n",
      "Epoch 3 Batch 1300 Loss 0.3949\n",
      "Epoch 3 Batch 1400 Loss 0.4048\n",
      "Epoch 3 Batch 1500 Loss 0.4123\n",
      "Epoch 3 Batch 1600 Loss 0.3868\n",
      "Epoch 3 Batch 1700 Loss 0.3680\n",
      "Epoch 3 Batch 1800 Loss 0.3415\n",
      "Epoch 3 Loss 0.4633\n",
      "Time taken for 1 epoch 241.35677862167358 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 0.2711\n",
      "Epoch 4 Batch 100 Loss 0.3319\n",
      "Epoch 4 Batch 200 Loss 0.2901\n",
      "Epoch 4 Batch 300 Loss 0.2635\n",
      "Epoch 4 Batch 400 Loss 0.3312\n",
      "Epoch 4 Batch 500 Loss 0.3924\n",
      "Epoch 4 Batch 600 Loss 0.2742\n",
      "Epoch 4 Batch 700 Loss 0.2803\n",
      "Epoch 4 Batch 800 Loss 0.3066\n",
      "Epoch 4 Batch 900 Loss 0.3183\n",
      "Epoch 4 Batch 1000 Loss 0.3289\n",
      "Epoch 4 Batch 1100 Loss 0.3216\n",
      "Epoch 4 Batch 1200 Loss 0.3474\n",
      "Epoch 4 Batch 1300 Loss 0.3707\n",
      "Epoch 4 Batch 1400 Loss 0.3022\n",
      "Epoch 4 Batch 1500 Loss 0.3713\n",
      "Epoch 4 Batch 1600 Loss 0.3013\n",
      "Epoch 4 Batch 1700 Loss 0.3035\n",
      "Epoch 4 Batch 1800 Loss 0.2797\n",
      "Epoch 4 Loss 0.3118\n",
      "Time taken for 1 epoch 241.93063235282898 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 0.1895\n",
      "Epoch 5 Batch 100 Loss 0.1804\n",
      "Epoch 5 Batch 200 Loss 0.2146\n",
      "Epoch 5 Batch 300 Loss 0.1952\n",
      "Epoch 5 Batch 400 Loss 0.2828\n",
      "Epoch 5 Batch 500 Loss 0.1492\n",
      "Epoch 5 Batch 600 Loss 0.2079\n",
      "Epoch 5 Batch 700 Loss 0.2280\n",
      "Epoch 5 Batch 800 Loss 0.2634\n",
      "Epoch 5 Batch 900 Loss 0.2021\n",
      "Epoch 5 Batch 1000 Loss 0.2198\n",
      "Epoch 5 Batch 1100 Loss 0.2004\n",
      "Epoch 5 Batch 1200 Loss 0.2312\n",
      "Epoch 5 Batch 1300 Loss 0.2659\n",
      "Epoch 5 Batch 1400 Loss 0.2900\n",
      "Epoch 5 Batch 1500 Loss 0.3062\n",
      "Epoch 5 Batch 1600 Loss 0.2642\n",
      "Epoch 5 Batch 1700 Loss 0.2393\n",
      "Epoch 5 Batch 1800 Loss 0.2320\n",
      "Epoch 5 Loss 0.2262\n",
      "Time taken for 1 epoch 240.6079456806183 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 0.1748\n",
      "Epoch 6 Batch 100 Loss 0.1420\n",
      "Epoch 6 Batch 200 Loss 0.1466\n",
      "Epoch 6 Batch 300 Loss 0.1406\n",
      "Epoch 6 Batch 400 Loss 0.1282\n",
      "Epoch 6 Batch 500 Loss 0.2074\n",
      "Epoch 6 Batch 600 Loss 0.1508\n",
      "Epoch 6 Batch 700 Loss 0.1760\n",
      "Epoch 6 Batch 800 Loss 0.1440\n",
      "Epoch 6 Batch 900 Loss 0.1674\n",
      "Epoch 6 Batch 1000 Loss 0.1723\n",
      "Epoch 6 Batch 1100 Loss 0.1395\n",
      "Epoch 6 Batch 1200 Loss 0.2009\n",
      "Epoch 6 Batch 1300 Loss 0.1675\n",
      "Epoch 6 Batch 1400 Loss 0.1727\n",
      "Epoch 6 Batch 1500 Loss 0.2183\n",
      "Epoch 6 Batch 1600 Loss 0.1917\n",
      "Epoch 6 Batch 1700 Loss 0.2608\n",
      "Epoch 6 Batch 1800 Loss 0.1890\n",
      "Epoch 6 Loss 0.1757\n",
      "Time taken for 1 epoch 241.90240669250488 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.1418\n",
      "Epoch 7 Batch 100 Loss 0.1298\n",
      "Epoch 7 Batch 200 Loss 0.1392\n",
      "Epoch 7 Batch 300 Loss 0.1166\n",
      "Epoch 7 Batch 400 Loss 0.1109\n",
      "Epoch 7 Batch 500 Loss 0.1875\n",
      "Epoch 7 Batch 600 Loss 0.1097\n",
      "Epoch 7 Batch 700 Loss 0.1322\n",
      "Epoch 7 Batch 800 Loss 0.1266\n",
      "Epoch 7 Batch 900 Loss 0.1369\n",
      "Epoch 7 Batch 1000 Loss 0.1980\n",
      "Epoch 7 Batch 1100 Loss 0.1499\n",
      "Epoch 7 Batch 1200 Loss 0.1829\n",
      "Epoch 7 Batch 1300 Loss 0.1238\n",
      "Epoch 7 Batch 1400 Loss 0.1575\n",
      "Epoch 7 Batch 1500 Loss 0.1527\n",
      "Epoch 7 Batch 1600 Loss 0.1321\n",
      "Epoch 7 Batch 1700 Loss 0.1563\n",
      "Epoch 7 Batch 1800 Loss 0.1401\n",
      "Epoch 7 Loss 0.1426\n",
      "Time taken for 1 epoch 240.3886013031006 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.1001\n",
      "Epoch 8 Batch 100 Loss 0.0774\n",
      "Epoch 8 Batch 200 Loss 0.0935\n",
      "Epoch 8 Batch 300 Loss 0.1047\n",
      "Epoch 8 Batch 400 Loss 0.1166\n",
      "Epoch 8 Batch 500 Loss 0.1301\n",
      "Epoch 8 Batch 600 Loss 0.1112\n",
      "Epoch 8 Batch 700 Loss 0.0968\n",
      "Epoch 8 Batch 800 Loss 0.0844\n",
      "Epoch 8 Batch 900 Loss 0.1509\n",
      "Epoch 8 Batch 1000 Loss 0.1146\n",
      "Epoch 8 Batch 1100 Loss 0.1168\n",
      "Epoch 8 Batch 1200 Loss 0.1469\n",
      "Epoch 8 Batch 1300 Loss 0.1410\n",
      "Epoch 8 Batch 1400 Loss 0.1215\n",
      "Epoch 8 Batch 1500 Loss 0.1489\n",
      "Epoch 8 Batch 1600 Loss 0.1279\n",
      "Epoch 8 Batch 1700 Loss 0.1328\n",
      "Epoch 8 Batch 1800 Loss 0.1739\n",
      "Epoch 8 Loss 0.1194\n",
      "Time taken for 1 epoch 241.85465288162231 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.1026\n",
      "Epoch 9 Batch 100 Loss 0.0800\n",
      "Epoch 9 Batch 200 Loss 0.0789\n",
      "Epoch 9 Batch 300 Loss 0.1195\n",
      "Epoch 9 Batch 400 Loss 0.0778\n",
      "Epoch 9 Batch 500 Loss 0.1008\n",
      "Epoch 9 Batch 600 Loss 0.0609\n",
      "Epoch 9 Batch 700 Loss 0.0902\n",
      "Epoch 9 Batch 800 Loss 0.1140\n",
      "Epoch 9 Batch 900 Loss 0.1153\n",
      "Epoch 9 Batch 1000 Loss 0.1311\n",
      "Epoch 9 Batch 1100 Loss 0.1069\n",
      "Epoch 9 Batch 1200 Loss 0.1343\n",
      "Epoch 9 Batch 1300 Loss 0.1145\n",
      "Epoch 9 Batch 1400 Loss 0.1300\n",
      "Epoch 9 Batch 1500 Loss 0.1359\n",
      "Epoch 9 Batch 1600 Loss 0.1713\n",
      "Epoch 9 Batch 1700 Loss 0.1328\n",
      "Epoch 9 Batch 1800 Loss 0.1733\n",
      "Epoch 9 Loss 0.1065\n",
      "Time taken for 1 epoch 241.26263809204102 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.0795\n",
      "Epoch 10 Batch 100 Loss 0.0755\n",
      "Epoch 10 Batch 200 Loss 0.0833\n",
      "Epoch 10 Batch 300 Loss 0.1093\n",
      "Epoch 10 Batch 400 Loss 0.0785\n",
      "Epoch 10 Batch 500 Loss 0.1032\n",
      "Epoch 10 Batch 600 Loss 0.0725\n",
      "Epoch 10 Batch 700 Loss 0.0769\n",
      "Epoch 10 Batch 800 Loss 0.1045\n",
      "Epoch 10 Batch 900 Loss 0.1383\n",
      "Epoch 10 Batch 1000 Loss 0.0899\n",
      "Epoch 10 Batch 1100 Loss 0.0882\n",
      "Epoch 10 Batch 1200 Loss 0.0717\n",
      "Epoch 10 Batch 1300 Loss 0.0891\n",
      "Epoch 10 Batch 1400 Loss 0.0831\n",
      "Epoch 10 Batch 1500 Loss 0.1140\n",
      "Epoch 10 Batch 1600 Loss 0.1169\n",
      "Epoch 10 Batch 1700 Loss 0.1157\n",
      "Epoch 10 Batch 1800 Loss 0.1233\n",
      "Epoch 10 Loss 0.0958\n",
      "Time taken for 1 epoch 242.03629565238953 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  start = time.time()\n",
    "\n",
    "  enc_hidden = encoder.initialize_hidden_state()\n",
    "  total_loss = 0\n",
    "\n",
    "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "    batch_loss = train_step(inp, targ, enc_hidden)\n",
    "    total_loss += batch_loss\n",
    "\n",
    "    if batch % 100 == 0:\n",
    "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                   batch,\n",
    "                                                   batch_loss.numpy()))\n",
    "  # saving (checkpoint) the model every 2 epochs\n",
    "  if (epoch + 1) % 2 == 0:\n",
    "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                      total_loss / steps_per_epoch))\n",
    "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2461410,
     "status": "ok",
     "timestamp": 1600199324716,
     "user": {
      "displayName": "Budhaditya Mukhopadhyay",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjhEyQYtB08E19TTD1GE25cdVV6J1caJTjg47JiCTg=s64",
      "userId": "05521750824977221992"
     },
     "user_tz": -120
    },
    "id": "IeVgdD4zTgb3"
   },
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "  attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "\n",
    "  sentence = preprocess_sentence(sentence)\n",
    "\n",
    "  inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
    "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                         maxlen=max_length_inp,\n",
    "                                                         padding='post')\n",
    "  inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "  result = ''\n",
    "\n",
    "  hidden = [tf.zeros((1, units))]\n",
    "  enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "  dec_hidden = enc_hidden\n",
    "  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
    "\n",
    "  for t in range(max_length_targ):\n",
    "    predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                         dec_hidden,\n",
    "                                                         enc_out)\n",
    "\n",
    "    # storing the attention weights to plot later on\n",
    "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "    attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "    result += targ_lang.index_word[predicted_id] + ' '\n",
    "\n",
    "    if targ_lang.index_word[predicted_id] == '<end>':\n",
    "      return result, sentence, attention_plot\n",
    "\n",
    "    # the predicted ID is fed back into the model\n",
    "    dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "  return result, sentence, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2461408,
     "status": "ok",
     "timestamp": 1600199324717,
     "user": {
      "displayName": "Budhaditya Mukhopadhyay",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjhEyQYtB08E19TTD1GE25cdVV6J1caJTjg47JiCTg=s64",
      "userId": "05521750824977221992"
     },
     "user_tz": -120
    },
    "id": "quTDuW-sTlNH"
   },
   "outputs": [],
   "source": [
    "# function for plotting the attention weights\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "  fig = plt.figure(figsize=(10,10))\n",
    "  ax = fig.add_subplot(1, 1, 1)\n",
    "  ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "  fontdict = {'fontsize': 14}\n",
    "\n",
    "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2461407,
     "status": "ok",
     "timestamp": 1600199324718,
     "user": {
      "displayName": "Budhaditya Mukhopadhyay",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjhEyQYtB08E19TTD1GE25cdVV6J1caJTjg47JiCTg=s64",
      "userId": "05521750824977221992"
     },
     "user_tz": -120
    },
    "id": "tsiddwD2TnHa"
   },
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "  result, sentence, attention_plot = evaluate(sentence)\n",
    "\n",
    "  print('Input: %s' % (sentence))\n",
    "  print('Predicted translation: {}'.format(result))\n",
    "\n",
    "  attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "  plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2461614,
     "status": "ok",
     "timestamp": 1600199324938,
     "user": {
      "displayName": "Budhaditya Mukhopadhyay",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjhEyQYtB08E19TTD1GE25cdVV6J1caJTjg47JiCTg=s64",
      "userId": "05521750824977221992"
     },
     "user_tz": -120
    },
    "id": "tw_Znwj_TqBY",
    "outputId": "dae4efbc-8815-4e16-9875-f9a4244ab01b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f240ebddfd0>"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restoring the latest checkpoint in checkpoint_dir\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 760
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2461930,
     "status": "ok",
     "timestamp": 1600199325266,
     "user": {
      "displayName": "Budhaditya Mukhopadhyay",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjhEyQYtB08E19TTD1GE25cdVV6J1caJTjg47JiCTg=s64",
      "userId": "05521750824977221992"
     },
     "user_tz": -120
    },
    "id": "1L8ZyEiWTtUU",
    "outputId": "28bef43e-61c0-4f47-b8a7-813ce0889b7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 24, 1)\n",
      "(1, 24, 1)\n",
      "(1, 24, 1)\n",
      "(1, 24, 1)\n",
      "(1, 24, 1)\n",
      "Input: <start> apfel ist rot . <end>\n",
      "Predicted translation: apples is red . <end> \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate(u'Apfel ist rot.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2461929,
     "status": "ok",
     "timestamp": 1600199325267,
     "user": {
      "displayName": "Budhaditya Mukhopadhyay",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjhEyQYtB08E19TTD1GE25cdVV6J1caJTjg47JiCTg=s64",
      "userId": "05521750824977221992"
     },
     "user_tz": -120
    },
    "id": "wv-wfotrTxnQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zApAR5iOLayA"
   },
   "source": [
    "## Luongs Multiplicative Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 927,
     "status": "ok",
     "timestamp": 1600202123334,
     "user": {
      "displayName": "Budhaditya Mukhopadhyay",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjhEyQYtB08E19TTD1GE25cdVV6J1caJTjg47JiCTg=s64",
      "userId": "05521750824977221992"
     },
     "user_tz": -120
    },
    "id": "KIqgCaO-gYUr"
   },
   "outputs": [],
   "source": [
    "class LuongsMultiplicativeAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self, units):\n",
    "    super(LuongsMultiplicativeAttention, self).__init__()\n",
    "    self.W = tf.keras.layers.Dense(units)\n",
    "\n",
    "  def call(self, query, values):\n",
    "    # query hidden state shape == (batch_size, hidden size)\n",
    "    # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "    # values shape == (batch_size, max_len, hidden size)\n",
    "    # we are doing this to broadcast addition along the time axis to calculate the score\n",
    "    \n",
    "    #query_with_time_axis = tf.expand_dims(query, 1)\n",
    "    #temp = tf.matmul(query_with_time_axis, self.W, transpose_a=True)  # (..., seq_len_q, seq_len_k)\n",
    "    temp = self.W(values)\n",
    "    #temp = tf.matmul(tf.transpose(query_with_time_axis),self.W)\n",
    "    query_with_time_axis = tf.expand_dims(query, 1)\n",
    "    score =  tf.matmul(temp, query_with_time_axis, transpose_b=True)\n",
    "    #score = query_with_time_axis * temp\n",
    "    print(temp.shape)\n",
    "    print(query_with_time_axis.shape)\n",
    "    print(score.shape)\n",
    "    #query_with_time_axis(T) * self.W1 * values\n",
    "    # score shape == (batch_size, max_length, 1)\n",
    "    # we get 1 at the last axis because we are applying score to self.V\n",
    "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
    "    #score = self.W1(query_with_time_axis) + self.W2(values)))\n",
    "\n",
    "    # attention_weights shape == (batch_size, max_length, 1)\n",
    "   \n",
    "    attention_weights = tf.nn.softmax(score, axis=1)\n",
    "    print(attention_weights.shape)\n",
    "    # context_vector shape after sum == (batch_size, hidden_size)\n",
    "    context_vector = attention_weights * values\n",
    "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "    return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2410,
     "status": "ok",
     "timestamp": 1600202126992,
     "user": {
      "displayName": "Budhaditya Mukhopadhyay",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjhEyQYtB08E19TTD1GE25cdVV6J1caJTjg47JiCTg=s64",
      "userId": "05521750824977221992"
     },
     "user_tz": -120
    },
    "id": "9Rh3oN4HA0GD",
    "outputId": "5dd0bc81-6497-461f-cfe3-fc57d8ebf22f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 24, 1024)\n",
      "(64, 1, 1024)\n",
      "(64, 24, 1)\n",
      "(64, 24, 1)\n",
      "Attention result shape: (batch size, units) (64, 1024)\n",
      "Attention weights shape: (batch_size, sequence_length, 1) (64, 24, 1)\n"
     ]
    }
   ],
   "source": [
    "attention_layer = LuongsMultiplicativeAttention(1024)\n",
    "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
    "\n",
    "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
    "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 665,
     "status": "ok",
     "timestamp": 1600202127666,
     "user": {
      "displayName": "Budhaditya Mukhopadhyay",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjhEyQYtB08E19TTD1GE25cdVV6J1caJTjg47JiCTg=s64",
      "userId": "05521750824977221992"
     },
     "user_tz": -120
    },
    "id": "ayUFDYT4MLM4"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "    super(Decoder, self).__init__()\n",
    "    self.batch_sz = batch_sz\n",
    "    self.dec_units = dec_units\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    # used for attention\n",
    "    self.attention = LuongsMultiplicativeAttention(self.dec_units)\n",
    "\n",
    "  def call(self, x, hidden, enc_output):\n",
    "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
    "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "\n",
    "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "    x = self.embedding(x)\n",
    "\n",
    "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "    # passing the concatenated vector to the GRU\n",
    "    output, state = self.gru(x)\n",
    "\n",
    "    # output shape == (batch_size * 1, hidden_size)\n",
    "    output = tf.reshape(output, (-1, output.shape[2]))\n",
    "\n",
    "    # output shape == (batch_size, vocab)\n",
    "    x = self.fc(output)\n",
    "\n",
    "    return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 945,
     "status": "ok",
     "timestamp": 1600202133345,
     "user": {
      "displayName": "Budhaditya Mukhopadhyay",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjhEyQYtB08E19TTD1GE25cdVV6J1caJTjg47JiCTg=s64",
      "userId": "05521750824977221992"
     },
     "user_tz": -120
    },
    "id": "ux4E12oKMPKW",
    "outputId": "112d980d-809e-4fa0-b8d2-c5e6c4c15353"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 24, 1024)\n",
      "(64, 1, 1024)\n",
      "(64, 24, 1)\n",
      "(64, 24, 1)\n",
      "Decoder output shape: (batch_size, vocab size) (64, 11205)\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
    "                                      sample_hidden, sample_output)\n",
    "\n",
    "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 699,
     "status": "ok",
     "timestamp": 1600202135852,
     "user": {
      "displayName": "Budhaditya Mukhopadhyay",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjhEyQYtB08E19TTD1GE25cdVV6J1caJTjg47JiCTg=s64",
      "userId": "05521750824977221992"
     },
     "user_tz": -120
    },
    "id": "4jg18A6fMPKY"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  loss_ = loss_object(real, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "  loss_ *= mask\n",
    "\n",
    "  return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 682,
     "status": "ok",
     "timestamp": 1600202137972,
     "user": {
      "displayName": "Budhaditya Mukhopadhyay",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjhEyQYtB08E19TTD1GE25cdVV6J1caJTjg47JiCTg=s64",
      "userId": "05521750824977221992"
     },
     "user_tz": -120
    },
    "id": "TZ98Zk7OMPKa"
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints_Luongs'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 993,
     "status": "ok",
     "timestamp": 1600202141611,
     "user": {
      "displayName": "Budhaditya Mukhopadhyay",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjhEyQYtB08E19TTD1GE25cdVV6J1caJTjg47JiCTg=s64",
      "userId": "05521750824977221992"
     },
     "user_tz": -120
    },
    "id": "ertsjHIhMPKc"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "  loss = 0\n",
    "\n",
    "  with tf.GradientTape() as tape:\n",
    "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "\n",
    "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "\n",
    "    # Teacher forcing - feeding the target as the next input\n",
    "    for t in range(1, targ.shape[1]):\n",
    "      # passing enc_output to the decoder\n",
    "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "\n",
    "      loss += loss_function(targ[:, t], predictions)\n",
    "\n",
    "      # using teacher forcing\n",
    "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "  batch_loss = (loss / int(targ.shape[1]))\n",
    "\n",
    "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "  gradients = tape.gradient(loss, variables)\n",
    "\n",
    "  optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "  return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "lVjsz8tFMPKe",
    "outputId": "0e8bbd0b-abf8-4b16-e25c-9a03335acdf1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 24, 1024)\n",
      "(64, 1, 1024)\n",
      "(64, 24, 1)\n",
      "(64, 24, 1)\n",
      "(64, 24, 1024)\n",
      "(64, 1, 1024)\n",
      "(64, 24, 1)\n",
      "(64, 24, 1)\n",
      "(64, 24, 1024)\n",
      "(64, 1, 1024)\n",
      "(64, 24, 1)\n",
      "(64, 24, 1)\n",
      "(64, 24, 1024)\n",
      "(64, 1, 1024)\n",
      "(64, 24, 1)\n",
      "(64, 24, 1)\n",
      "(64, 24, 1024)\n",
      "(64, 1, 1024)\n",
      "(64, 24, 1)\n",
      "(64, 24, 1)\n",
      "(64, 24, 1024)\n",
      "(64, 1, 1024)\n",
      "(64, 24, 1)\n",
      "(64, 24, 1)\n",
      "(64, 24, 1024)\n",
      "(64, 1, 1024)\n",
      "(64, 24, 1)\n",
      "(64, 24, 1)\n",
      "(64, 24, 1024)\n",
      "(64, 1, 1024)\n",
      "(64, 24, 1)\n",
      "(64, 24, 1)\n",
      "(64, 24, 1024)\n",
      "(64, 1, 1024)\n",
      "(64, 24, 1)\n",
      "(64, 24, 1)\n",
      "(64, 24, 1024)\n",
      "(64, 1, 1024)\n",
      "(64, 24, 1)\n",
      "(64, 24, 1)\n",
      "(64, 24, 1024)\n",
      "(64, 1, 1024)\n",
      "(64, 24, 1)\n",
      "(64, 24, 1)\n",
      "(64, 24, 1024)\n",
      "(64, 1, 1024)\n",
      "(64, 24, 1)\n",
      "(64, 24, 1)\n",
      "(64, 24, 1024)\n",
      "(64, 1, 1024)\n",
      "(64, 24, 1)\n",
      "(64, 24, 1)\n",
      "(64, 24, 1024)\n",
      "(64, 1, 1024)\n",
      "(64, 24, 1)\n",
      "(64, 24, 1)\n",
      "(64, 24, 1024)\n",
      "(64, 1, 1024)\n",
      "(64, 24, 1)\n",
      "(64, 24, 1)\n",
      "(64, 24, 1024)\n",
      "(64, 1, 1024)\n",
      "(64, 24, 1)\n",
      "(64, 24, 1)\n",
      "(64, 24, 1024)\n",
      "(64, 1, 1024)\n",
      "(64, 24, 1)\n",
      "(64, 24, 1)\n",
      "(64, 24, 1024)\n",
      "(64, 1, 1024)\n",
      "(64, 24, 1)\n",
      "(64, 24, 1)\n",
      "(64, 24, 1024)\n",
      "(64, 1, 1024)\n",
      "(64, 24, 1)\n",
      "(64, 24, 1)\n",
      "(64, 24, 1024)\n",
      "(64, 1, 1024)\n",
      "(64, 24, 1)\n",
      "(64, 24, 1)\n",
      "(64, 24, 1024)\n",
      "(64, 1, 1024)\n",
      "(64, 24, 1)\n",
      "(64, 24, 1)\n",
      "(64, 24, 1024)\n",
      "(64, 1, 1024)\n",
      "(64, 24, 1)\n",
      "(64, 24, 1)\n",
      "(64, 24, 1024)\n",
      "(64, 1, 1024)\n",
      "(64, 24, 1)\n",
      "(64, 24, 1)\n",
      "(64, 24, 1024)\n",
      "(64, 1, 1024)\n",
      "(64, 24, 1)\n",
      "(64, 24, 1)\n",
      "(64, 24, 1024)\n",
      "(64, 1, 1024)\n",
      "(64, 24, 1)\n",
      "(64, 24, 1)\n",
      "(64, 24, 1024)\n",
      "(64, 1, 1024)\n",
      "(64, 24, 1)\n",
      "(64, 24, 1)\n",
      "Epoch 1 Batch 0 Loss 4.9418\n",
      "Epoch 1 Batch 100 Loss 2.1464\n",
      "Epoch 1 Batch 200 Loss 1.6568\n",
      "Epoch 1 Batch 300 Loss 1.3658\n",
      "Epoch 1 Batch 400 Loss 1.2139\n",
      "Epoch 1 Batch 500 Loss 1.0192\n",
      "Epoch 1 Batch 600 Loss 1.1485\n",
      "Epoch 1 Batch 700 Loss 1.1685\n",
      "Epoch 1 Batch 800 Loss 1.2361\n",
      "Epoch 1 Batch 900 Loss 0.9484\n",
      "Epoch 1 Batch 1000 Loss 0.8577\n",
      "Epoch 1 Batch 1100 Loss 1.0672\n",
      "Epoch 1 Batch 1200 Loss 0.7873\n",
      "Epoch 1 Batch 1300 Loss 0.8467\n",
      "Epoch 1 Batch 1400 Loss 0.8778\n",
      "Epoch 1 Batch 1500 Loss 0.9804\n",
      "Epoch 1 Batch 1600 Loss 0.8995\n",
      "Epoch 1 Batch 1700 Loss 0.8349\n",
      "Epoch 1 Batch 1800 Loss 0.7978\n",
      "Epoch 1 Loss 1.1456\n",
      "Time taken for 1 epoch 255.88112425804138 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 0.7059\n",
      "Epoch 2 Batch 100 Loss 0.7584\n",
      "Epoch 2 Batch 200 Loss 0.7017\n",
      "Epoch 2 Batch 300 Loss 0.6310\n",
      "Epoch 2 Batch 400 Loss 0.7053\n",
      "Epoch 2 Batch 500 Loss 0.6313\n",
      "Epoch 2 Batch 600 Loss 0.8536\n",
      "Epoch 2 Batch 700 Loss 0.7419\n",
      "Epoch 2 Batch 800 Loss 0.8972\n",
      "Epoch 2 Batch 900 Loss 0.8273\n",
      "Epoch 2 Batch 1000 Loss 0.9322\n",
      "Epoch 2 Batch 1100 Loss 1.0044\n",
      "Epoch 2 Batch 1200 Loss 0.9890\n",
      "Epoch 2 Batch 1300 Loss 0.8438\n",
      "Epoch 2 Batch 1400 Loss 0.8905\n",
      "Epoch 2 Batch 1500 Loss 0.7359\n",
      "Epoch 2 Batch 1600 Loss 0.7866\n",
      "Epoch 2 Batch 1700 Loss 0.8290\n",
      "Epoch 2 Batch 1800 Loss 0.8625\n",
      "Epoch 2 Loss 0.8035\n",
      "Time taken for 1 epoch 243.6887013912201 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 0.6887\n",
      "Epoch 3 Batch 100 Loss 0.7674\n",
      "Epoch 3 Batch 200 Loss 0.6307\n",
      "Epoch 3 Batch 300 Loss 0.6264\n",
      "Epoch 3 Batch 400 Loss 0.5995\n",
      "Epoch 3 Batch 500 Loss 0.6986\n",
      "Epoch 3 Batch 600 Loss 0.5791\n",
      "Epoch 3 Batch 700 Loss 0.5609\n",
      "Epoch 3 Batch 800 Loss 0.6663\n",
      "Epoch 3 Batch 900 Loss 0.6881\n",
      "Epoch 3 Batch 1000 Loss 0.6675\n",
      "Epoch 3 Batch 1100 Loss 0.5162\n",
      "Epoch 3 Batch 1200 Loss 0.5503\n",
      "Epoch 3 Batch 1300 Loss 0.5459\n",
      "Epoch 3 Batch 1400 Loss 0.6184\n",
      "Epoch 3 Batch 1500 Loss 0.5390\n",
      "Epoch 3 Batch 1600 Loss 0.6976\n",
      "Epoch 3 Batch 1700 Loss 0.6577\n",
      "Epoch 3 Batch 1800 Loss 0.6155\n",
      "Epoch 3 Loss 0.6206\n",
      "Time taken for 1 epoch 242.52881979942322 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 0.4420\n",
      "Epoch 4 Batch 100 Loss 0.4939\n",
      "Epoch 4 Batch 200 Loss 0.5048\n",
      "Epoch 4 Batch 300 Loss 0.4876\n",
      "Epoch 4 Batch 400 Loss 0.4518\n",
      "Epoch 4 Batch 500 Loss 0.4868\n",
      "Epoch 4 Batch 600 Loss 0.4662\n",
      "Epoch 4 Batch 700 Loss 0.4683\n",
      "Epoch 4 Batch 800 Loss 0.4489\n",
      "Epoch 4 Batch 900 Loss 0.5299\n",
      "Epoch 4 Batch 1000 Loss 0.3976\n",
      "Epoch 4 Batch 1100 Loss 0.4945\n",
      "Epoch 4 Batch 1200 Loss 0.6353\n",
      "Epoch 4 Batch 1300 Loss 0.4295\n",
      "Epoch 4 Batch 1400 Loss 0.3799\n",
      "Epoch 4 Batch 1500 Loss 0.4970\n",
      "Epoch 4 Batch 1600 Loss 0.3986\n",
      "Epoch 4 Batch 1700 Loss 0.5791\n",
      "Epoch 4 Batch 1800 Loss 0.6018\n",
      "Epoch 4 Loss 0.4721\n",
      "Time taken for 1 epoch 243.8432538509369 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 0.3571\n",
      "Epoch 5 Batch 100 Loss 0.4086\n",
      "Epoch 5 Batch 200 Loss 0.3537\n",
      "Epoch 5 Batch 300 Loss 0.3079\n",
      "Epoch 5 Batch 400 Loss 0.4406\n",
      "Epoch 5 Batch 500 Loss 0.4605\n",
      "Epoch 5 Batch 600 Loss 0.4340\n",
      "Epoch 5 Batch 700 Loss 0.3850\n",
      "Epoch 5 Batch 800 Loss 0.3386\n",
      "Epoch 5 Batch 900 Loss 0.3874\n",
      "Epoch 5 Batch 1000 Loss 0.4094\n",
      "Epoch 5 Batch 1100 Loss 0.3643\n",
      "Epoch 5 Batch 1200 Loss 0.3791\n",
      "Epoch 5 Batch 1300 Loss 0.3252\n",
      "Epoch 5 Batch 1400 Loss 0.4616\n",
      "Epoch 5 Batch 1500 Loss 0.3302\n",
      "Epoch 5 Batch 1600 Loss 0.4142\n",
      "Epoch 5 Batch 1700 Loss 0.4267\n",
      "Epoch 5 Batch 1800 Loss 0.3465\n",
      "Epoch 5 Loss 0.4039\n",
      "Time taken for 1 epoch 242.8049397468567 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 0.4163\n",
      "Epoch 6 Batch 100 Loss 0.3573\n",
      "Epoch 6 Batch 200 Loss 0.3045\n",
      "Epoch 6 Batch 300 Loss 0.3722\n",
      "Epoch 6 Batch 400 Loss 0.3520\n",
      "Epoch 6 Batch 500 Loss 0.3702\n",
      "Epoch 6 Batch 600 Loss 0.3799\n",
      "Epoch 6 Batch 700 Loss 0.3390\n",
      "Epoch 6 Batch 800 Loss 0.2953\n",
      "Epoch 6 Batch 900 Loss 0.3858\n",
      "Epoch 6 Batch 1000 Loss 0.3431\n",
      "Epoch 6 Batch 1100 Loss 0.3668\n",
      "Epoch 6 Batch 1200 Loss 0.3371\n",
      "Epoch 6 Batch 1300 Loss 0.3940\n",
      "Epoch 6 Batch 1400 Loss 0.3195\n",
      "Epoch 6 Batch 1500 Loss 0.4425\n",
      "Epoch 6 Batch 1600 Loss 0.4054\n",
      "Epoch 6 Batch 1700 Loss 0.3841\n",
      "Epoch 6 Batch 1800 Loss 0.3201\n",
      "Epoch 6 Loss 0.3558\n",
      "Time taken for 1 epoch 243.83545398712158 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.3116\n",
      "Epoch 7 Batch 100 Loss 0.2188\n",
      "Epoch 7 Batch 200 Loss 0.3378\n",
      "Epoch 7 Batch 300 Loss 0.3389\n",
      "Epoch 7 Batch 400 Loss 0.2187\n",
      "Epoch 7 Batch 500 Loss 0.4090\n",
      "Epoch 7 Batch 600 Loss 0.2462\n",
      "Epoch 7 Batch 700 Loss 0.3096\n",
      "Epoch 7 Batch 800 Loss 0.2773\n",
      "Epoch 7 Batch 900 Loss 0.3704\n",
      "Epoch 7 Batch 1000 Loss 0.3468\n",
      "Epoch 7 Batch 1100 Loss 0.2561\n",
      "Epoch 7 Batch 1200 Loss 0.2895\n",
      "Epoch 7 Batch 1300 Loss 0.3614\n",
      "Epoch 7 Batch 1400 Loss 0.3015\n",
      "Epoch 7 Batch 1500 Loss 0.3063\n",
      "Epoch 7 Batch 1600 Loss 0.3494\n",
      "Epoch 7 Batch 1700 Loss 0.3870\n",
      "Epoch 7 Batch 1800 Loss 0.3315\n",
      "Epoch 7 Loss 0.3251\n",
      "Time taken for 1 epoch 243.020192861557 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.1764\n",
      "Epoch 8 Batch 100 Loss 0.2479\n",
      "Epoch 8 Batch 200 Loss 0.2725\n",
      "Epoch 8 Batch 300 Loss 0.2420\n",
      "Epoch 8 Batch 400 Loss 0.2600\n",
      "Epoch 8 Batch 500 Loss 0.2434\n",
      "Epoch 8 Batch 600 Loss 0.2533\n",
      "Epoch 8 Batch 700 Loss 0.3161\n",
      "Epoch 8 Batch 800 Loss 0.3039\n",
      "Epoch 8 Batch 900 Loss 0.2824\n",
      "Epoch 8 Batch 1000 Loss 0.3038\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  start = time.time()\n",
    "\n",
    "  enc_hidden = encoder.initialize_hidden_state()\n",
    "  total_loss = 0\n",
    "\n",
    "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "    batch_loss = train_step(inp, targ, enc_hidden)\n",
    "    total_loss += batch_loss\n",
    "\n",
    "    if batch % 100 == 0:\n",
    "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                   batch,\n",
    "                                                   batch_loss.numpy()))\n",
    "  # saving (checkpoint) the model every 2 epochs\n",
    "  if (epoch + 1) % 2 == 0:\n",
    "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                      total_loss / steps_per_epoch))\n",
    "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 662,
     "status": "ok",
     "timestamp": 1600202154201,
     "user": {
      "displayName": "Budhaditya Mukhopadhyay",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjhEyQYtB08E19TTD1GE25cdVV6J1caJTjg47JiCTg=s64",
      "userId": "05521750824977221992"
     },
     "user_tz": -120
    },
    "id": "o_1SE10BMPKi"
   },
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "  attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "\n",
    "  sentence = preprocess_sentence(sentence)\n",
    "\n",
    "  inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
    "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                         maxlen=max_length_inp,\n",
    "                                                         padding='post')\n",
    "  inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "  result = ''\n",
    "\n",
    "  hidden = [tf.zeros((1, units))]\n",
    "  enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "  dec_hidden = enc_hidden\n",
    "  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
    "\n",
    "  for t in range(max_length_targ):\n",
    "    predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                         dec_hidden,\n",
    "                                                         enc_out)\n",
    "\n",
    "    # storing the attention weights to plot later on\n",
    "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "    attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "    result += targ_lang.index_word[predicted_id] + ' '\n",
    "\n",
    "    if targ_lang.index_word[predicted_id] == '<end>':\n",
    "      return result, sentence, attention_plot\n",
    "\n",
    "    # the predicted ID is fed back into the model\n",
    "    dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "  return result, sentence, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 780,
     "status": "ok",
     "timestamp": 1600202159932,
     "user": {
      "displayName": "Budhaditya Mukhopadhyay",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjhEyQYtB08E19TTD1GE25cdVV6J1caJTjg47JiCTg=s64",
      "userId": "05521750824977221992"
     },
     "user_tz": -120
    },
    "id": "XqfBT41-MPKl"
   },
   "outputs": [],
   "source": [
    "# function for plotting the attention weights\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "  fig = plt.figure(figsize=(10,10))\n",
    "  ax = fig.add_subplot(1, 1, 1)\n",
    "  ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "  fontdict = {'fontsize': 14}\n",
    "\n",
    "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 656,
     "status": "ok",
     "timestamp": 1600202162009,
     "user": {
      "displayName": "Budhaditya Mukhopadhyay",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjhEyQYtB08E19TTD1GE25cdVV6J1caJTjg47JiCTg=s64",
      "userId": "05521750824977221992"
     },
     "user_tz": -120
    },
    "id": "ivmkJzIVMPKm"
   },
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "  result, sentence, attention_plot = evaluate(sentence)\n",
    "\n",
    "  print('Input: %s' % (sentence))\n",
    "  print('Predicted translation: {}'.format(result))\n",
    "\n",
    "  attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "  plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 908,
     "status": "ok",
     "timestamp": 1600202164381,
     "user": {
      "displayName": "Budhaditya Mukhopadhyay",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjhEyQYtB08E19TTD1GE25cdVV6J1caJTjg47JiCTg=s64",
      "userId": "05521750824977221992"
     },
     "user_tz": -120
    },
    "id": "2II1ubRBMPKo",
    "outputId": "c6bfda1c-5441-4828-da2b-7e8af6501760"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.InitializationOnlyStatus at 0x7f944aab18d0>"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restoring the latest checkpoint in checkpoint_dir\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1318,
     "status": "ok",
     "timestamp": 1600202168641,
     "user": {
      "displayName": "Budhaditya Mukhopadhyay",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjhEyQYtB08E19TTD1GE25cdVV6J1caJTjg47JiCTg=s64",
      "userId": "05521750824977221992"
     },
     "user_tz": -120
    },
    "id": "r0eR9InoMPKq",
    "outputId": "5189c17e-1522-4dee-c6d4-5d2ac0cf2e84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 24, 1024)\n",
      "(1, 1, 1024)\n",
      "(1, 24, 1)\n",
      "(1, 24, 1)\n",
      "(1, 24, 1024)\n",
      "(1, 1, 1024)\n",
      "(1, 24, 1)\n",
      "(1, 24, 1)\n",
      "(1, 24, 1024)\n",
      "(1, 1, 1024)\n",
      "(1, 24, 1)\n",
      "(1, 24, 1)\n",
      "(1, 24, 1024)\n",
      "(1, 1, 1024)\n",
      "(1, 24, 1)\n",
      "(1, 24, 1)\n",
      "(1, 24, 1024)\n",
      "(1, 1, 1024)\n",
      "(1, 24, 1)\n",
      "(1, 24, 1)\n",
      "(1, 24, 1024)\n",
      "(1, 1, 1024)\n",
      "(1, 24, 1)\n",
      "(1, 24, 1)\n",
      "(1, 24, 1024)\n",
      "(1, 1, 1024)\n",
      "(1, 24, 1)\n",
      "(1, 24, 1)\n",
      "(1, 24, 1024)\n",
      "(1, 1, 1024)\n",
      "(1, 24, 1)\n",
      "(1, 24, 1)\n",
      "(1, 24, 1024)\n",
      "(1, 1, 1024)\n",
      "(1, 24, 1)\n",
      "(1, 24, 1)\n",
      "(1, 24, 1024)\n",
      "(1, 1, 1024)\n",
      "(1, 24, 1)\n",
      "(1, 24, 1)\n",
      "(1, 24, 1024)\n",
      "(1, 1, 1024)\n",
      "(1, 24, 1)\n",
      "(1, 24, 1)\n",
      "(1, 24, 1024)\n",
      "(1, 1, 1024)\n",
      "(1, 24, 1)\n",
      "(1, 24, 1)\n",
      "(1, 24, 1024)\n",
      "(1, 1, 1024)\n",
      "(1, 24, 1)\n",
      "(1, 24, 1)\n",
      "(1, 24, 1024)\n",
      "(1, 1, 1024)\n",
      "(1, 24, 1)\n",
      "(1, 24, 1)\n",
      "Input: <start> apfel ist rot . <end>\n",
      "Predicted translation: verdict quickest petition gauge zookeeper dissatisfaction haven magda governed shouts believes passed zookeeper dissatisfaction \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate(u'Apfel ist rot.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dfTFT9NWLfkY"
   },
   "source": [
    "## Dot Product Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 635,
     "status": "ok",
     "timestamp": 1600202174257,
     "user": {
      "displayName": "Budhaditya Mukhopadhyay",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjhEyQYtB08E19TTD1GE25cdVV6J1caJTjg47JiCTg=s64",
      "userId": "05521750824977221992"
     },
     "user_tz": -120
    },
    "id": "MsZExWbJATPs"
   },
   "outputs": [],
   "source": [
    "class DotProductAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self, units):\n",
    "    super(DotProductAttention, self).__init__()\n",
    "    self.W = tf.keras.layers.Dense(units)\n",
    "\n",
    "  def call(self, query, values):\n",
    "    query_with_time_axis = tf.expand_dims(query, 1)\n",
    "    score =  tf.matmul(values,query_with_time_axis, transpose_b=True)\n",
    "    attention_weights = tf.nn.softmax(score, axis=1)\n",
    "    context_vector = attention_weights * values\n",
    "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "    \n",
    "    return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 683,
     "status": "ok",
     "timestamp": 1600202176322,
     "user": {
      "displayName": "Budhaditya Mukhopadhyay",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjhEyQYtB08E19TTD1GE25cdVV6J1caJTjg47JiCTg=s64",
      "userId": "05521750824977221992"
     },
     "user_tz": -120
    },
    "id": "pPGVQ_Q7jm9d",
    "outputId": "b969c4f8-c8b8-4b85-d406-67af95af0cf0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention result shape: (batch size, units) (64, 1024)\n",
      "Attention weights shape: (batch_size, sequence_length, 1) (64, 24, 1)\n"
     ]
    }
   ],
   "source": [
    "attention_layer = DotProductAttention(1024)\n",
    "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
    "\n",
    "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
    "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 742,
     "status": "ok",
     "timestamp": 1600202179904,
     "user": {
      "displayName": "Budhaditya Mukhopadhyay",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjhEyQYtB08E19TTD1GE25cdVV6J1caJTjg47JiCTg=s64",
      "userId": "05521750824977221992"
     },
     "user_tz": -120
    },
    "id": "QyL52-VvNpD6"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "    super(Decoder, self).__init__()\n",
    "    self.batch_sz = batch_sz\n",
    "    self.dec_units = dec_units\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    # used for attention\n",
    "    self.attention = DotProductAttention(self.dec_units)\n",
    "\n",
    "\n",
    "  def call(self, x, hidden, enc_output):\n",
    "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
    "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "\n",
    "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "    x = self.embedding(x)\n",
    "\n",
    "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "    # passing the concatenated vector to the GRU\n",
    "    output, state = self.gru(x)\n",
    "\n",
    "    # output shape == (batch_size * 1, hidden_size)\n",
    "    output = tf.reshape(output, (-1, output.shape[2]))\n",
    "\n",
    "    # output shape == (batch_size, vocab)\n",
    "    x = self.fc(output)\n",
    "\n",
    "    return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 717,
     "status": "ok",
     "timestamp": 1600202182207,
     "user": {
      "displayName": "Budhaditya Mukhopadhyay",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjhEyQYtB08E19TTD1GE25cdVV6J1caJTjg47JiCTg=s64",
      "userId": "05521750824977221992"
     },
     "user_tz": -120
    },
    "id": "TArkIZoXNpD-",
    "outputId": "4d0cf5c4-8331-40c8-dc3b-84d90cd5afac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: (batch_size, vocab size) (64, 11205)\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
    "                                      sample_hidden, sample_output)\n",
    "\n",
    "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 722,
     "status": "ok",
     "timestamp": 1600202201675,
     "user": {
      "displayName": "Budhaditya Mukhopadhyay",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjhEyQYtB08E19TTD1GE25cdVV6J1caJTjg47JiCTg=s64",
      "userId": "05521750824977221992"
     },
     "user_tz": -120
    },
    "id": "y-Qs7bztNpEA"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  loss_ = loss_object(real, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "  loss_ *= mask\n",
    "\n",
    "  return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 671,
     "status": "ok",
     "timestamp": 1600202203760,
     "user": {
      "displayName": "Budhaditya Mukhopadhyay",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjhEyQYtB08E19TTD1GE25cdVV6J1caJTjg47JiCTg=s64",
      "userId": "05521750824977221992"
     },
     "user_tz": -120
    },
    "id": "rzaJtEl-NpEB"
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints_Luongs'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 758,
     "status": "ok",
     "timestamp": 1600202205884,
     "user": {
      "displayName": "Budhaditya Mukhopadhyay",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjhEyQYtB08E19TTD1GE25cdVV6J1caJTjg47JiCTg=s64",
      "userId": "05521750824977221992"
     },
     "user_tz": -120
    },
    "id": "rGipv1D5NpED"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "  loss = 0\n",
    "\n",
    "  with tf.GradientTape() as tape:\n",
    "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "\n",
    "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "\n",
    "    # Teacher forcing - feeding the target as the next input\n",
    "    for t in range(1, targ.shape[1]):\n",
    "      # passing enc_output to the decoder\n",
    "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "\n",
    "      loss += loss_function(targ[:, t], predictions)\n",
    "\n",
    "      # using teacher forcing\n",
    "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "  batch_loss = (loss / int(targ.shape[1]))\n",
    "\n",
    "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "  gradients = tape.gradient(loss, variables)\n",
    "\n",
    "  optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "  return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2709094,
     "status": "ok",
     "timestamp": 1600204916766,
     "user": {
      "displayName": "Budhaditya Mukhopadhyay",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjhEyQYtB08E19TTD1GE25cdVV6J1caJTjg47JiCTg=s64",
      "userId": "05521750824977221992"
     },
     "user_tz": -120
    },
    "id": "7OGgb7yONpEF",
    "outputId": "599b59f2-b602-4d90-8dac-a7dd240658a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 4.9635\n",
      "Epoch 1 Batch 100 Loss 2.5449\n",
      "Epoch 1 Batch 200 Loss 2.1980\n",
      "Epoch 1 Batch 300 Loss 2.1924\n",
      "Epoch 1 Batch 400 Loss 1.9817\n",
      "Epoch 1 Batch 500 Loss 1.7522\n",
      "Epoch 1 Batch 600 Loss 1.6632\n",
      "Epoch 1 Batch 700 Loss 1.5089\n",
      "Epoch 1 Batch 800 Loss 1.6933\n",
      "Epoch 1 Batch 900 Loss 1.5791\n",
      "Epoch 1 Batch 1000 Loss 1.4389\n",
      "Epoch 1 Batch 1100 Loss 1.5292\n",
      "Epoch 1 Batch 1200 Loss 1.5129\n",
      "Epoch 1 Batch 1300 Loss 1.3115\n",
      "Epoch 1 Batch 1400 Loss 1.3613\n",
      "Epoch 1 Batch 1500 Loss 1.3547\n",
      "Epoch 1 Batch 1600 Loss 1.2338\n",
      "Epoch 1 Batch 1700 Loss 1.2335\n",
      "Epoch 1 Batch 1800 Loss 1.1881\n",
      "Epoch 1 Loss 1.6372\n",
      "Time taken for 1 epoch 284.8163137435913 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 1.1936\n",
      "Epoch 2 Batch 100 Loss 1.0333\n",
      "Epoch 2 Batch 200 Loss 0.9958\n",
      "Epoch 2 Batch 300 Loss 0.8707\n",
      "Epoch 2 Batch 400 Loss 1.0018\n",
      "Epoch 2 Batch 500 Loss 0.9451\n",
      "Epoch 2 Batch 600 Loss 0.9598\n",
      "Epoch 2 Batch 700 Loss 0.9520\n",
      "Epoch 2 Batch 800 Loss 0.8908\n",
      "Epoch 2 Batch 900 Loss 0.9786\n",
      "Epoch 2 Batch 1000 Loss 0.9139\n",
      "Epoch 2 Batch 1100 Loss 0.7897\n",
      "Epoch 2 Batch 1200 Loss 0.9810\n",
      "Epoch 2 Batch 1300 Loss 0.9284\n",
      "Epoch 2 Batch 1400 Loss 0.7114\n",
      "Epoch 2 Batch 1500 Loss 0.8511\n",
      "Epoch 2 Batch 1600 Loss 0.7818\n",
      "Epoch 2 Batch 1700 Loss 0.8421\n",
      "Epoch 2 Batch 1800 Loss 0.7321\n",
      "Epoch 2 Loss 0.9220\n",
      "Time taken for 1 epoch 270.5007779598236 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 0.6911\n",
      "Epoch 3 Batch 100 Loss 0.6314\n",
      "Epoch 3 Batch 200 Loss 0.5724\n",
      "Epoch 3 Batch 300 Loss 0.6212\n",
      "Epoch 3 Batch 400 Loss 0.6804\n",
      "Epoch 3 Batch 500 Loss 0.5929\n",
      "Epoch 3 Batch 600 Loss 0.6376\n",
      "Epoch 3 Batch 700 Loss 0.6149\n",
      "Epoch 3 Batch 800 Loss 0.5943\n",
      "Epoch 3 Batch 900 Loss 0.6468\n",
      "Epoch 3 Batch 1000 Loss 0.6862\n",
      "Epoch 3 Batch 1100 Loss 0.4711\n",
      "Epoch 3 Batch 1200 Loss 0.6281\n",
      "Epoch 3 Batch 1300 Loss 0.5591\n",
      "Epoch 3 Batch 1400 Loss 0.5606\n",
      "Epoch 3 Batch 1500 Loss 0.5519\n",
      "Epoch 3 Batch 1600 Loss 0.5317\n",
      "Epoch 3 Batch 1700 Loss 0.5261\n",
      "Epoch 3 Batch 1800 Loss 0.6516\n",
      "Epoch 3 Loss 0.5952\n",
      "Time taken for 1 epoch 269.2893090248108 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 0.4488\n",
      "Epoch 4 Batch 100 Loss 0.3736\n",
      "Epoch 4 Batch 200 Loss 0.4044\n",
      "Epoch 4 Batch 300 Loss 0.4524\n",
      "Epoch 4 Batch 400 Loss 0.3484\n",
      "Epoch 4 Batch 500 Loss 0.3600\n",
      "Epoch 4 Batch 600 Loss 0.4481\n",
      "Epoch 4 Batch 700 Loss 0.4645\n",
      "Epoch 4 Batch 800 Loss 0.3414\n",
      "Epoch 4 Batch 900 Loss 0.3328\n",
      "Epoch 4 Batch 1000 Loss 0.4563\n",
      "Epoch 4 Batch 1100 Loss 0.4004\n",
      "Epoch 4 Batch 1200 Loss 0.3442\n",
      "Epoch 4 Batch 1300 Loss 0.4094\n",
      "Epoch 4 Batch 1400 Loss 0.3858\n",
      "Epoch 4 Batch 1500 Loss 0.4789\n",
      "Epoch 4 Batch 1600 Loss 0.3780\n",
      "Epoch 4 Batch 1700 Loss 0.4255\n",
      "Epoch 4 Batch 1800 Loss 0.3553\n",
      "Epoch 4 Loss 0.4137\n",
      "Time taken for 1 epoch 270.43649315834045 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 0.2429\n",
      "Epoch 5 Batch 100 Loss 0.3333\n",
      "Epoch 5 Batch 200 Loss 0.3104\n",
      "Epoch 5 Batch 300 Loss 0.3272\n",
      "Epoch 5 Batch 400 Loss 0.2970\n",
      "Epoch 5 Batch 500 Loss 0.3287\n",
      "Epoch 5 Batch 600 Loss 0.2507\n",
      "Epoch 5 Batch 700 Loss 0.3229\n",
      "Epoch 5 Batch 800 Loss 0.2630\n",
      "Epoch 5 Batch 900 Loss 0.3410\n",
      "Epoch 5 Batch 1000 Loss 0.2849\n",
      "Epoch 5 Batch 1100 Loss 0.2487\n",
      "Epoch 5 Batch 1200 Loss 0.2937\n",
      "Epoch 5 Batch 1300 Loss 0.3871\n",
      "Epoch 5 Batch 1400 Loss 0.3285\n",
      "Epoch 5 Batch 1500 Loss 0.3366\n",
      "Epoch 5 Batch 1600 Loss 0.3035\n",
      "Epoch 5 Batch 1700 Loss 0.3341\n",
      "Epoch 5 Batch 1800 Loss 0.3875\n",
      "Epoch 5 Loss 0.3031\n",
      "Time taken for 1 epoch 269.00302171707153 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 0.2141\n",
      "Epoch 6 Batch 100 Loss 0.2709\n",
      "Epoch 6 Batch 200 Loss 0.2322\n",
      "Epoch 6 Batch 300 Loss 0.1995\n",
      "Epoch 6 Batch 400 Loss 0.2208\n",
      "Epoch 6 Batch 500 Loss 0.2559\n",
      "Epoch 6 Batch 600 Loss 0.1958\n",
      "Epoch 6 Batch 700 Loss 0.2373\n",
      "Epoch 6 Batch 800 Loss 0.2598\n",
      "Epoch 6 Batch 900 Loss 0.2443\n",
      "Epoch 6 Batch 1000 Loss 0.2088\n",
      "Epoch 6 Batch 1100 Loss 0.2111\n",
      "Epoch 6 Batch 1200 Loss 0.2800\n",
      "Epoch 6 Batch 1300 Loss 0.2852\n",
      "Epoch 6 Batch 1400 Loss 0.2109\n",
      "Epoch 6 Batch 1500 Loss 0.2478\n",
      "Epoch 6 Batch 1600 Loss 0.2268\n",
      "Epoch 6 Batch 1700 Loss 0.2069\n",
      "Epoch 6 Batch 1800 Loss 0.2561\n",
      "Epoch 6 Loss 0.2355\n",
      "Time taken for 1 epoch 269.39316511154175 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.1519\n",
      "Epoch 7 Batch 100 Loss 0.1588\n",
      "Epoch 7 Batch 200 Loss 0.1784\n",
      "Epoch 7 Batch 300 Loss 0.1349\n",
      "Epoch 7 Batch 400 Loss 0.2153\n",
      "Epoch 7 Batch 500 Loss 0.1613\n",
      "Epoch 7 Batch 600 Loss 0.1874\n",
      "Epoch 7 Batch 700 Loss 0.2228\n",
      "Epoch 7 Batch 800 Loss 0.1738\n",
      "Epoch 7 Batch 900 Loss 0.1539\n",
      "Epoch 7 Batch 1000 Loss 0.1855\n",
      "Epoch 7 Batch 1100 Loss 0.1517\n",
      "Epoch 7 Batch 1200 Loss 0.1619\n",
      "Epoch 7 Batch 1300 Loss 0.2193\n",
      "Epoch 7 Batch 1400 Loss 0.2863\n",
      "Epoch 7 Batch 1500 Loss 0.1696\n",
      "Epoch 7 Batch 1600 Loss 0.2034\n",
      "Epoch 7 Batch 1700 Loss 0.1823\n",
      "Epoch 7 Batch 1800 Loss 0.1964\n",
      "Epoch 7 Loss 0.1873\n",
      "Time taken for 1 epoch 268.75506615638733 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.1338\n",
      "Epoch 8 Batch 100 Loss 0.1636\n",
      "Epoch 8 Batch 200 Loss 0.1447\n",
      "Epoch 8 Batch 300 Loss 0.1491\n",
      "Epoch 8 Batch 400 Loss 0.1448\n",
      "Epoch 8 Batch 500 Loss 0.1408\n",
      "Epoch 8 Batch 600 Loss 0.1507\n",
      "Epoch 8 Batch 700 Loss 0.1589\n",
      "Epoch 8 Batch 800 Loss 0.1402\n",
      "Epoch 8 Batch 900 Loss 0.1684\n",
      "Epoch 8 Batch 1000 Loss 0.1388\n",
      "Epoch 8 Batch 1100 Loss 0.1988\n",
      "Epoch 8 Batch 1200 Loss 0.1668\n",
      "Epoch 8 Batch 1300 Loss 0.1683\n",
      "Epoch 8 Batch 1400 Loss 0.1878\n",
      "Epoch 8 Batch 1500 Loss 0.1601\n",
      "Epoch 8 Batch 1600 Loss 0.2351\n",
      "Epoch 8 Batch 1700 Loss 0.1660\n",
      "Epoch 8 Batch 1800 Loss 0.1705\n",
      "Epoch 8 Loss 0.1543\n",
      "Time taken for 1 epoch 269.27593326568604 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.1222\n",
      "Epoch 9 Batch 100 Loss 0.0975\n",
      "Epoch 9 Batch 200 Loss 0.1402\n",
      "Epoch 9 Batch 300 Loss 0.0648\n",
      "Epoch 9 Batch 400 Loss 0.1036\n",
      "Epoch 9 Batch 500 Loss 0.1132\n",
      "Epoch 9 Batch 600 Loss 0.1672\n",
      "Epoch 9 Batch 700 Loss 0.0995\n",
      "Epoch 9 Batch 800 Loss 0.1226\n",
      "Epoch 9 Batch 900 Loss 0.1261\n",
      "Epoch 9 Batch 1000 Loss 0.1444\n",
      "Epoch 9 Batch 1100 Loss 0.1339\n",
      "Epoch 9 Batch 1200 Loss 0.1335\n",
      "Epoch 9 Batch 1300 Loss 0.1415\n",
      "Epoch 9 Batch 1400 Loss 0.1006\n",
      "Epoch 9 Batch 1500 Loss 0.1276\n",
      "Epoch 9 Batch 1600 Loss 0.1406\n",
      "Epoch 9 Batch 1700 Loss 0.1479\n",
      "Epoch 9 Batch 1800 Loss 0.1297\n",
      "Epoch 9 Loss 0.1313\n",
      "Time taken for 1 epoch 267.90217304229736 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.0885\n",
      "Epoch 10 Batch 100 Loss 0.1015\n",
      "Epoch 10 Batch 200 Loss 0.0871\n",
      "Epoch 10 Batch 300 Loss 0.0899\n",
      "Epoch 10 Batch 400 Loss 0.1084\n",
      "Epoch 10 Batch 500 Loss 0.0902\n",
      "Epoch 10 Batch 600 Loss 0.1034\n",
      "Epoch 10 Batch 700 Loss 0.0966\n",
      "Epoch 10 Batch 800 Loss 0.1212\n",
      "Epoch 10 Batch 900 Loss 0.1204\n",
      "Epoch 10 Batch 1000 Loss 0.0820\n",
      "Epoch 10 Batch 1100 Loss 0.0911\n",
      "Epoch 10 Batch 1200 Loss 0.1372\n",
      "Epoch 10 Batch 1300 Loss 0.1879\n",
      "Epoch 10 Batch 1400 Loss 0.1430\n",
      "Epoch 10 Batch 1500 Loss 0.1412\n",
      "Epoch 10 Batch 1600 Loss 0.1391\n",
      "Epoch 10 Batch 1700 Loss 0.1293\n",
      "Epoch 10 Batch 1800 Loss 0.1452\n",
      "Epoch 10 Loss 0.1153\n",
      "Time taken for 1 epoch 269.03380584716797 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  start = time.time()\n",
    "\n",
    "  enc_hidden = encoder.initialize_hidden_state()\n",
    "  total_loss = 0\n",
    "\n",
    "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "    batch_loss = train_step(inp, targ, enc_hidden)\n",
    "    total_loss += batch_loss\n",
    "\n",
    "    if batch % 100 == 0:\n",
    "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                   batch,\n",
    "                                                   batch_loss.numpy()))\n",
    "  # saving (checkpoint) the model every 2 epochs\n",
    "  if (epoch + 1) % 2 == 0:\n",
    "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                      total_loss / steps_per_epoch))\n",
    "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 781,
     "status": "ok",
     "timestamp": 1600204978217,
     "user": {
      "displayName": "Budhaditya Mukhopadhyay",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjhEyQYtB08E19TTD1GE25cdVV6J1caJTjg47JiCTg=s64",
      "userId": "05521750824977221992"
     },
     "user_tz": -120
    },
    "id": "3nMOFmfUNpEH"
   },
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "  attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "\n",
    "  sentence = preprocess_sentence(sentence)\n",
    "\n",
    "  inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
    "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                         maxlen=max_length_inp,\n",
    "                                                         padding='post')\n",
    "  inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "  result = ''\n",
    "\n",
    "  hidden = [tf.zeros((1, units))]\n",
    "  enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "  dec_hidden = enc_hidden\n",
    "  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
    "\n",
    "  for t in range(max_length_targ):\n",
    "    predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                         dec_hidden,\n",
    "                                                         enc_out)\n",
    "\n",
    "    # storing the attention weights to plot later on\n",
    "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "    attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "    result += targ_lang.index_word[predicted_id] + ' '\n",
    "\n",
    "    if targ_lang.index_word[predicted_id] == '<end>':\n",
    "      return result, sentence, attention_plot\n",
    "\n",
    "    # the predicted ID is fed back into the model\n",
    "    dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "  return result, sentence, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 716,
     "status": "ok",
     "timestamp": 1600204980569,
     "user": {
      "displayName": "Budhaditya Mukhopadhyay",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjhEyQYtB08E19TTD1GE25cdVV6J1caJTjg47JiCTg=s64",
      "userId": "05521750824977221992"
     },
     "user_tz": -120
    },
    "id": "u7yDrARBNpEJ"
   },
   "outputs": [],
   "source": [
    "# function for plotting the attention weights\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "  fig = plt.figure(figsize=(10,10))\n",
    "  ax = fig.add_subplot(1, 1, 1)\n",
    "  ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "  fontdict = {'fontsize': 14}\n",
    "\n",
    "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 760,
     "status": "ok",
     "timestamp": 1600204995534,
     "user": {
      "displayName": "Budhaditya Mukhopadhyay",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjhEyQYtB08E19TTD1GE25cdVV6J1caJTjg47JiCTg=s64",
      "userId": "05521750824977221992"
     },
     "user_tz": -120
    },
    "id": "qZeAJV-_NpEL"
   },
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "  result, sentence, attention_plot = evaluate(sentence)\n",
    "\n",
    "  print('Input: %s' % (sentence))\n",
    "  print('Predicted translation: {}'.format(result))\n",
    "\n",
    "  attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "  plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 763,
     "status": "ok",
     "timestamp": 1600204997761,
     "user": {
      "displayName": "Budhaditya Mukhopadhyay",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjhEyQYtB08E19TTD1GE25cdVV6J1caJTjg47JiCTg=s64",
      "userId": "05521750824977221992"
     },
     "user_tz": -120
    },
    "id": "uzV9NiF6NpEN",
    "outputId": "7f5bf22f-1ea4-48b2-b5cf-c95053a39352"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f944a90ce80>"
      ]
     },
     "execution_count": 54,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restoring the latest checkpoint in checkpoint_dir\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 676
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 746,
     "status": "ok",
     "timestamp": 1600205109754,
     "user": {
      "displayName": "Budhaditya Mukhopadhyay",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjhEyQYtB08E19TTD1GE25cdVV6J1caJTjg47JiCTg=s64",
      "userId": "05521750824977221992"
     },
     "user_tz": -120
    },
    "id": "9cI7yp1NNpEP",
    "outputId": "54e2bfcd-a76b-4c36-d0b0-d13827d2ac30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> apfel ist rot . <end>\n",
      "Predicted translation: red is red . <end> \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate(u'Apfel ist rot.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4UL5ChedVfrD"
   },
   "source": [
    "# Assignment questions -\n",
    "\n",
    "\n",
    "- Which parts of the sentence are used as a token? Each character, each word, or are some words split up?  \n",
    "Answer: Each word is used as a token. No words are split up during the formation of tokens. During pre-processing, all special characters except \".\", \"?\", \"!\", \",\" are removed. All alphabets are retained. The pre-processing also takes into consideration the extra german alphabets.\n",
    "<br>\n",
    "<br>\n",
    "- Do the same tokens in different language have the same ID?\n",
    "e.g. Would the same token index map to the German word die and to the English word die?  \n",
    "Answer: The tokens that are same in both the languages, do not have the same ID. As per the example given below, the token \"die\" has different IDs.<br>\n",
    "<pre>\n",
    "Input Language; index to word mapping\n",
    "1 ----> <start>\n",
    "12 ----> du\n",
    "44 ----> hast\n",
    "33 ----> eine\n",
    "3791 ----> alternative\n",
    "3 ----> .\n",
    "2 ----> <end>\n",
    "</pre>\n",
    "<pre>\n",
    "Target Language; index to word mapping\n",
    "1 ----> <start>\n",
    "6 ----> you\n",
    "20 ----> have\n",
    "82 ----> an\n",
    "3392 ----> alternative\n",
    "3 ----> .\n",
    "2 ----> <end>\n",
    "</pre>\n",
    "<br>\n",
    "<br>\n",
    "- What is the relation between the encoder output and the encoder hidden state which is used to initialize the decoder hidden state?\n",
    "(for the architecture used in the tutorial)  \n",
    "Answer:  The model reads the input sequence one at a time, and builds the hidden state for each input. However, the output of this model is only generated when the input sequence is completely processed, thus making the model asynchronous. This output is generated by applying a transformation on the last hidden state, which now contains all the information about the input sequence contents. The output will then be compared with the desired output y, in order to generate the loss value. The output is not a sequence anymore, but is a single value in vector format.\n",
    "<br>\n",
    "<br>\n",
    "- Is the decoder attending to all previous positions, including the previous decoder predictions?  \n",
    "Answer: The decoder has input from output of previous timestep, usually with output-to-hidden connections. The decoder takes into consideration the previous predictions, while computing for the current timestep.\n",
    "<br>\n",
    "<br>\n",
    "- Does the Encoder output change in different decoding steps?  \n",
    "Answer: During decoding process, if the output is not as expected, then by backpropagation, gradients can travel upto the encoder that contributed to the information that was used to make the prediction at that time. Thus the encoder output may change for different decoding steps.\n",
    "<br>\n",
    "<br>\n",
    "- Does the context vector change in different decoding steps?  \n",
    "Answer: Yes, the context vector is dynamic and changes for each decoding step. The context vector is the aggregated attention of the weighted sum of the encoder hidden states. During the decoding steps, it is possible to have updated attention weights, which in turn lead to an updated context vector.\n",
    "<br>\n",
    "<br>\n",
    "- The decoder uses teacher forcing. Does this mean the time steps can be computed in parallel?  \n",
    "Answer: In teacher forcing, the expected output is concatenated with the actual output, and passed to the next timestep. This still needs the sequential input from the previous timestep, and therefore the computation cannot be parallelized. RNNs can only be parallelized if all the connections are ground-truth to hidden connections.\n",
    "<br>\n",
    "<br>\n",
    "- Why is a mask applied to the loss function?  \n",
    "The samples provided as input are not of the same length. We pad the input before the training so as to make the input of a standard length. Masking is a way to tell sequence-processing layers that certain timesteps in an input are missing, and thus should be skipped when processing the data. "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMk3URZ7GP7+ekqXJ/vc2Vg",
   "collapsed_sections": [],
   "mount_file_id": "1TzosA5s_H3CsK3AOBuaJqt6TjNIXB-Ir",
   "name": "TASK_5.ipynb",
   "provenance": [
    {
     "file_id": "1Uei5so0Cf8Bt95esXK-I2-Ak1vixJldJ",
     "timestamp": 1599420269634
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
