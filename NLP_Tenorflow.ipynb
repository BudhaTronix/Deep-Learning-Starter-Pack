{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Tenorflow.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "9acDfvhGXfrc",
        "qFhYQkIsCZqd"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xnA8rt7c0Ai",
        "colab_type": "text"
      },
      "source": [
        "### **Assignment 6**\n",
        " -- Chirag Mandal (229958) & Budhaditya Mukhopadhyay (229960)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlvKU33NYC8r",
        "colab_type": "text"
      },
      "source": [
        "## **Part 1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZbfnduvr2vz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZ7ERkqKrdPq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from prepare_data2 import parse_seq\n",
        "import pickle\n",
        "os.chdir('/content/drive/My Drive/Colab Notebooks/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n02SjVYwX-PW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DIRECTORY_URL = 'https://colab.research.google.com/drive/19QD1mqnqKQ-C-TXfznrJYGjpY9uoTC2I#scrollTo=mYRlhuwuIVl7'\n",
        "FILE_NAMES = ['shakespeare.txt']\n",
        "\n",
        "for name in FILE_NAMES:\n",
        "  text_dir = tf.keras.utils.get_file(name, origin=DIRECTORY_URL+name)\n",
        "  \n",
        "parent_dir = os.path.dirname(text_dir)\n",
        "\n",
        "parent_dir\n",
        "!python prepare_data2.py in.txt out.txt [0-9]+:[0-9]+"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "708AzM2hYCXe",
        "colab_type": "code",
        "outputId": "b338efa2-39ca-4de3-b7c0-5680deb7e854",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        }
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "# this is just a datasets of \"bytes\" (not understandable)\n",
        "data = tf.data.TFRecordDataset(\"out.txt.tfrecords\")\n",
        "\n",
        "# this maps a parser function that properly interprets the bytes over the dataset\n",
        "# (with fixed sequence length 200)\n",
        "# if you change the sequence length in preprocessing you also need to change it here\n",
        "data = data.map(lambda x: parse_seq(x, 200)) \n",
        "\n",
        "# a map from characters to indices\n",
        "vocab = pickle.load(open(\"out.txt_vocab\", mode=\"rb\"))\n",
        "vocab_size = len(vocab)\n",
        "# inverse mapping: indices to characters\n",
        "ind_to_ch = {ind: ch for (ch, ind) in vocab.items()}\n",
        "print(vocab)\n",
        "print(vocab_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-adbdef61fc6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mprepare_data2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mparse_seq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'prepare_data2'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OioqsevP8_i",
        "colab_type": "code",
        "outputId": "ac41e7dc-c4ad-4058-f86b-6ca4bfa5d5f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "data = tf.data.TFRecordDataset(raw_dataset)\n",
        "# a map from characters to indices\n",
        "vocab = pickle.load(open(\"out.txt_vocab\", mode=\"rb\"))\n",
        "vocab_size = len(vocab)\n",
        "# inverse mapping: indices to characters\n",
        "ind_to_ch = {ind: ch for (ch, ind) in vocab.items()}\n",
        "print(vocab)\n",
        "print(vocab_size)\n",
        "# The unique characters in the file\n",
        "a = sorted(set(vocab))\n",
        "print ('{} unique characters'.format(len(a)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'I': 3, 'N': 4, 'C': 5, '8': 6, 'x': 7, '\\n': 8, 's': 9, 'O': 10, 'a': 11, '5': 12, '6': 13, '-': 14, 'Z': 15, 'e': 16, 'y': 17, 'P': 18, 'n': 19, 'D': 20, 'o': 21, 'B': 22, 'G': 23, 'K': 24, 'Q': 25, ';': 26, 'Y': 27, 'v': 28, 'i': 29, 'd': 30, 'k': 31, '.': 32, 'r': 33, '0': 34, ')': 35, '3': 36, 'u': 37, 'U': 38, ' ': 39, 'S': 40, 'E': 41, \"'\": 42, 'z': 43, '9': 44, 'F': 45, 'm': 46, 't': 47, 'l': 48, 'q': 49, 'A': 50, '1': 51, 'L': 52, 'M': 53, '(': 54, 'f': 55, 'b': 56, 'c': 57, 'g': 58, 'W': 59, '4': 60, 'V': 61, 'h': 62, '7': 63, 'p': 64, 'j': 65, 'J': 66, ',': 67, '!': 68, '*': 69, 'T': 70, '2': 71, '?': 72, 'H': 73, 'R': 74, ':': 75, 'w': 76, '<PAD>': 0, '<S>': 1, '</S>': 2}\n",
            "77\n",
            "77 unique characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeppQhdbYCrz",
        "colab_type": "code",
        "outputId": "9316c1bf-59fc-43c2-f0d0-42308f75c45c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "batch_count = 0\n",
        "for batch_x in data.shuffle(100000).padded_batch(128, padded_shapes=None, padding_values=None, drop_remainder=True):batch_count=batch_count+1\n",
        "print(\"new Batch\",batch_count)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "new Batch 242\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXHlt2DJYKzm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rnn(learning_rate, seqlen, epochs):\n",
        "  hidden_size = 512\n",
        "  opt = tf.keras.optimizers.Adam()\n",
        "  W_xh = tf.Variable((np.random.randn(vocab_size, hidden_size)).astype('float32')*0.01)\n",
        "  W_hh = tf.Variable((np.random.randn(hidden_size,hidden_size)).astype('float32')*0.01)\n",
        "  W_ho = tf.Variable((np.random.randn(hidden_size,vocab_size)).astype('float32')*0.01)\n",
        "  b_h = tf.Variable(np.zeros((1, hidden_size), dtype= 'float32'))\n",
        "  b_o = tf.Variable(np.zeros((1, vocab_size), dtype= 'float32'))\n",
        "  h_init = tf.Variable((np.random.randn(1,hidden_size)).astype('float32')*0.01)\n",
        "  for epoch in range(epochs):\n",
        "    batch_count = 0\n",
        "    for batch_x in data.shuffle(100000).batch(128, drop_remainder=True):\n",
        "      print(\"new Batch\",batch_count)\n",
        "      x_seq = batch_x\n",
        "      seq_loss = 0\n",
        "      with tf.GradientTape() as tape:\n",
        "        for i in range(1,seqlen):\n",
        "          time_step = i-1\n",
        "          x1 = tf.one_hot(x_seq, vocab_size)\n",
        "          y = x_seq[:,time_step+1]\n",
        "          y1 = tf.one_hot(y, vocab_size)\n",
        "          x_seq_t = x1[:,time_step,:]\n",
        "          h_init = tf.matmul(x_seq_t, W_xh)+tf.matmul(h_init, W_hh)+b_h\n",
        "          h_init = tf.nn.tanh(h_init)\n",
        "          logits = tf.matmul(h_init, W_ho) + b_o\n",
        "          loss_char = tf.nn.softmax_cross_entropy_with_logits(labels = y1, logits = logits)\n",
        "          mean = tf.reduce_mean(loss_char)\n",
        "          seq_loss += mean\n",
        "      grads = tape.gradient(seq_loss, [W_xh, W_hh, W_ho, b_h, b_o])\n",
        "      opt.apply_gradients(zip(grads, [W_xh, W_hh, W_ho, b_h, b_o]))\n",
        "      '''Wih.assign_sub(grads[0]*learning_rate)\n",
        "      Whh.assign_sub(grads[1]*learning_rate)\n",
        "      Wyh.assign_sub(grads[2]*learning_rate)\n",
        "      bh.assign_sub(grads[3]*learning_rate)\n",
        "      bo.assign_sub(grads[4]*learning_rate)'''\n",
        "      print(\"Epoch :{}, Average error: {} \".format(epoch,seq_loss/seqlen))\n",
        "      batch_count +=1\n",
        "  Trained_weights = np.array([W_xh, W_hh, W_ho, b_h, b_o])\n",
        "  np.save('rnn_weights', Trained_weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCV-crC7YOP9",
        "colab_type": "code",
        "outputId": "c6373ac4-345e-46a6-98b4-ad226e57372c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "rnn(0.001, 150, 1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "new Batch 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-116-9bdf304098c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-115-ace852e9903d>\u001b[0m in \u001b[0;36mrnn\u001b[0;34m(learning_rate, seqlen, epochs)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseqlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m           \u001b[0mtime_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m           \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m           \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_seq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtime_step\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m           \u001b[0my1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mone_hot\u001b[0;34m(indices, depth, on_value, off_value, axis, dtype, name)\u001b[0m\n\u001b[1;32m   4008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4009\u001b[0m     return gen_array_ops.one_hot(indices, depth, on_value, off_value, axis,\n\u001b[0;32m-> 4010\u001b[0;31m                                  name)\n\u001b[0m\u001b[1;32m   4011\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mone_hot\u001b[0;34m(indices, depth, on_value, off_value, axis, name)\u001b[0m\n\u001b[1;32m   6191\u001b[0m         \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6192\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6193\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6194\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6195\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6651\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6652\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6653\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6654\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
            "\u001b[0;31mNotFoundError\u001b[0m: Could not find valid device for node.\nNode:{{node OneHot}}\nAll kernels registered for op OneHot :\n  device='XLA_CPU'; TI in [DT_INT32, DT_UINT8, DT_INT64]; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, ..., DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]\n  device='XLA_CPU_JIT'; TI in [DT_INT32, DT_UINT8, DT_INT64]; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, ..., DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]\n  device='XLA_GPU_JIT'; TI in [DT_INT32, DT_UINT8, DT_INT64]; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, ..., DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]\n  device='XLA_GPU'; TI in [DT_INT32, DT_UINT8, DT_INT64]; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, ..., DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]\n  device='CPU'; TI in [DT_INT64]; T in [DT_VARIANT]\n  device='CPU'; TI in [DT_INT32]; T in [DT_VARIANT]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_VARIANT]\n  device='CPU'; TI in [DT_INT64]; T in [DT_RESOURCE]\n  device='CPU'; TI in [DT_INT32]; T in [DT_RESOURCE]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_RESOURCE]\n  device='CPU'; TI in [DT_INT64]; T in [DT_STRING]\n  device='CPU'; TI in [DT_INT32]; T in [DT_STRING]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_STRING]\n  device='CPU'; TI in [DT_INT64]; T in [DT_BOOL]\n  device='CPU'; TI in [DT_INT32]; T in [DT_BOOL]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_BOOL]\n  device='CPU'; TI in [DT_INT64]; T in [DT_COMPLEX128]\n  device='CPU'; TI in [DT_INT32]; T in [DT_COMPLEX128]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_COMPLEX128]\n  device='CPU'; TI in [DT_INT64]; T in [DT_COMPLEX64]\n  device='CPU'; TI in [DT_INT32]; T in [DT_COMPLEX64]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_COMPLEX64]\n  device='CPU'; TI in [DT_INT64]; T in [DT_DOUBLE]\n  device='CPU'; TI in [DT_INT32]; T in [DT_DOUBLE]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_DOUBLE]\n  device='CPU'; TI in [DT_INT64]; T in [DT_FLOAT]\n  device='CPU'; TI in [DT_INT32]; T in [DT_FLOAT]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_FLOAT]\n  device='CPU'; TI in [DT_INT64]; T in [DT_BFLOAT16]\n  device='CPU'; TI in [DT_INT32]; T in [DT_BFLOAT16]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_BFLOAT16]\n  device='CPU'; TI in [DT_INT64]; T in [DT_HALF]\n  device='CPU'; TI in [DT_INT32]; T in [DT_HALF]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_HALF]\n  device='CPU'; TI in [DT_INT64]; T in [DT_INT8]\n  device='CPU'; TI in [DT_INT32]; T in [DT_INT8]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_INT8]\n  device='CPU'; TI in [DT_INT64]; T in [DT_UINT8]\n  device='CPU'; TI in [DT_INT32]; T in [DT_UINT8]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_UINT8]\n  device='CPU'; TI in [DT_INT64]; T in [DT_INT16]\n  device='CPU'; TI in [DT_INT32]; T in [DT_INT16]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_INT16]\n  device='CPU'; TI in [DT_INT64]; T in [DT_UINT16]\n  device='CPU'; TI in [DT_INT32]; T in [DT_UINT16]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_UINT16]\n  device='CPU'; TI in [DT_INT64]; T in [DT_INT32]\n  device='CPU'; TI in [DT_INT32]; T in [DT_INT32]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_INT32]\n  device='CPU'; TI in [DT_INT64]; T in [DT_INT64]\n  device='CPU'; TI in [DT_INT32]; T in [DT_INT64]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_INT64]\n  device='GPU'; TI in [DT_INT64]; T in [DT_INT64]\n  device='GPU'; TI in [DT_INT32]; T in [DT_INT64]\n  device='GPU'; TI in [DT_UINT8]; T in [DT_INT64]\n  device='GPU'; TI in [DT_INT64]; T in [DT_INT32]\n  device='GPU'; TI in [DT_INT32]; T in [DT_INT32]\n  device='GPU'; TI in [DT_UINT8]; T in [DT_INT32]\n  device='GPU'; TI in [DT_INT64]; T in [DT_BOOL]\n  device='GPU'; TI in [DT_INT32]; T in [DT_BOOL]\n  device='GPU'; TI in [DT_UINT8]; T in [DT_BOOL]\n  device='GPU'; TI in [DT_INT64]; T in [DT_DOUBLE]\n  device='GPU'; TI in [DT_INT32]; T in [DT_DOUBLE]\n  device='GPU'; TI in [DT_UINT8]; T in [DT_DOUBLE]\n  device='GPU'; TI in [DT_INT64]; T in [DT_FLOAT]\n  device='GPU'; TI in [DT_INT32]; T in [DT_FLOAT]\n  device='GPU'; TI in [DT_UINT8]; T in [DT_FLOAT]\n  device='GPU'; TI in [DT_INT64]; T in [DT_HALF]\n  device='GPU'; TI in [DT_INT32]; T in [DT_HALF]\n  device='GPU'; TI in [DT_UINT8]; T in [DT_HALF]\n [Op:OneHot]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E45VPWUrZBts",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weights = np.load('rnn_weights.npy', allow_pickle = True)\n",
        "[W_xh, W_hh, W_ho, b_h, b_o] = weights\n",
        "h_init = tf.Variable((np.random.randn(1,512)).astype('float32')*0.01)\n",
        "char = np.zeros((1,vocab_size),dtype= 'float32')\n",
        "char[0][0] = 1\n",
        "finalString = \"\"\n",
        "\n",
        "for i in range (1000):\n",
        "  h_init = tf.matmul(char, W_xh)+tf.matmul(h_init, W_hh)+b_h\n",
        "  h_init = tf.nn.tanh(h_init)\n",
        "  logits = tf.matmul(h_init, W_ho)+b_o\n",
        "  prob = np.exp(logits) / np.sum(np.exp(logits))             #softmax function\n",
        "  idx = np.random.choice(range(vocab_size), p=prob.ravel())  #returns a list of vocab_size elements taken at random from prob into idx\n",
        "  char = np.zeros((1,vocab_size),dtype= 'float32')\n",
        "  char[0][idx] = 1\n",
        "  op = ind_to_ch[idx]            #index to characters\n",
        "  finalString += op               \n",
        "print(finalString)  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9acDfvhGXfrc",
        "colab_type": "text"
      },
      "source": [
        "## **Part 2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LraD7h_0_sMJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "from keras.utils.data_utils import get_file\n",
        "os.chdir('/content/drive/My Drive/Colab Notebooks/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FH6jvWjf_t7a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_to_file = tf.keras.utils.get_file('the-king-james-bible.txt', 'https://raw.githubusercontent.com/ErikSchierboom/sentencegenerator/master/samples/the-king-james-bible.txt')\n",
        "#path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mod0WVlVAE5_",
        "colab_type": "code",
        "outputId": "42886907-aa4e-4b38-8c13-c335f32e2861",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Read, then decode for py2 compat.\n",
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "print ('Length of text: {} characters'.format(len(text)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of text: 4332497 characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCQeZRTvAFbp",
        "colab_type": "code",
        "outputId": "a689291a-f2d8-4057-c4e8-25f6a1fc2637",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# Take a look at the first 250 characters in text\n",
        "print(text[:250])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "﻿The First Book of Moses:  Called Genesis\n",
            "\n",
            "\n",
            "1:1 In the beginning God created the heaven and the earth.\n",
            "\n",
            "1:2 And the earth was without form, and void; and darkness was upon\n",
            "the face of the deep. And the Spirit of God moved upon the face of the\n",
            "waters.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8xUfiuCAG96",
        "colab_type": "code",
        "outputId": "35ee9a12-005a-413f-e2d0-92f898434262",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# The unique characters in the file\n",
        "vocab = sorted(set(text))\n",
        "print ('{} unique characters'.format(len(vocab)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "75 unique characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOJe96xaAJcr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating a mapping from unique characters to indices\n",
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "\n",
        "text_as_int = np.array([char2idx[c] for c in text])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nEdRRBPAM2H",
        "colab_type": "code",
        "outputId": "97c58c9f-bbea-45e9-aee5-3f791c2f4ff3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "print('{')\n",
        "for char,_ in zip(char2idx, range(20)):\n",
        "    print('  {:4s}: {:3d},'.format(repr(char), char2idx[char]))\n",
        "print('  ...\\n}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  '\\n':   0,\n",
            "  ' ' :   1,\n",
            "  '!' :   2,\n",
            "  \"'\" :   3,\n",
            "  '(' :   4,\n",
            "  ')' :   5,\n",
            "  '*' :   6,\n",
            "  ',' :   7,\n",
            "  '-' :   8,\n",
            "  '.' :   9,\n",
            "  '0' :  10,\n",
            "  '1' :  11,\n",
            "  '2' :  12,\n",
            "  '3' :  13,\n",
            "  '4' :  14,\n",
            "  '5' :  15,\n",
            "  '6' :  16,\n",
            "  '7' :  17,\n",
            "  '8' :  18,\n",
            "  '9' :  19,\n",
            "  ...\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sEjF3jhAPON",
        "colab_type": "code",
        "outputId": "5a84e456-4d0a-4009-eeb5-8b89cdf7829a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Show how the first 13 characters from the text are mapped to integers\n",
        "print ('{} ---- characters mapped to int ---- > {}'.format(repr(text[:13]), text_as_int[:13]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'\\ufeffThe First Bo' ---- characters mapped to int ---- > [74 42 55 52  1 28 56 65 66 67  1 24 62]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDDjXDxSARXC",
        "colab_type": "code",
        "outputId": "db6d3a34-2858-4eed-a685-06c53b6916f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# The maximum length sentence we want for a single input in characters\n",
        "seq_length = 100\n",
        "examples_per_epoch = len(text)//(seq_length+1)\n",
        "\n",
        "# Create training examples / targets\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
        "\n",
        "for i in char_dataset.take(5):\n",
        "  print(idx2char[i.numpy()])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "﻿\n",
            "T\n",
            "h\n",
            "e\n",
            " \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-hzSfCSAWf4",
        "colab_type": "code",
        "outputId": "dc35b04a-09c7-41a1-ec7c-b01a8e852a9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "#sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "sequences = char_dataset.padded_batch(seq_length+1, padded_shapes=None, padding_values=None, drop_remainder=True)\n",
        "\n",
        "for item in sequences.take(5):\n",
        "  print(repr(''.join(idx2char[item.numpy()])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'\\ufeffThe First Book of Moses:  Called Genesis\\n\\n\\n1:1 In the beginning God created the heaven and the earth'\n",
            "'.\\n\\n1:2 And the earth was without form, and void; and darkness was upon\\nthe face of the deep. And the '\n",
            "'Spirit of God moved upon the face of the\\nwaters.\\n\\n1:3 And God said, Let there be light: and there was'\n",
            "' light.\\n\\n1:4 And God saw the light, that it was good: and God divided the light\\nfrom the darkness.\\n\\n1'\n",
            "':5 And God called the light Day, and the darkness he called Night.\\nAnd the evening and the morning we'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tqniNcmAdMW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_input_target(chunk):\n",
        "    input_text = chunk[:-1]\n",
        "    target_text = chunk[1:]\n",
        "    return input_text, target_text\n",
        "\n",
        "dataset = sequences.map(split_input_target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bnr78nowAgSQ",
        "colab_type": "code",
        "outputId": "07484d17-1336-496d-fceb-03f18ea7fe1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "for input_example, target_example in  dataset.take(1):\n",
        "  print ('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
        "  print ('Target data:', repr(''.join(idx2char[target_example.numpy()])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input data:  '\\ufeffThe First Book of Moses:  Called Genesis\\n\\n\\n1:1 In the beginning God created the heaven and the eart'\n",
            "Target data: 'The First Book of Moses:  Called Genesis\\n\\n\\n1:1 In the beginning God created the heaven and the earth'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqprwHWuAiPk",
        "colab_type": "code",
        "outputId": "f35ba03f-07a7-4d17-bf62-dc538966c6fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "for i, (input_idx, target_idx) in enumerate(zip(input_example[:5], target_example[:5])):\n",
        "    print(\"Step {:4d}\".format(i))\n",
        "    print(\"  input: {} ({:s})\".format(input_idx, repr(idx2char[input_idx])))\n",
        "    print(\"  expected output: {} ({:s})\".format(target_idx, repr(idx2char[target_idx])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step    0\n",
            "  input: 74 ('\\ufeff')\n",
            "  expected output: 42 ('T')\n",
            "Step    1\n",
            "  input: 42 ('T')\n",
            "  expected output: 55 ('h')\n",
            "Step    2\n",
            "  input: 55 ('h')\n",
            "  expected output: 52 ('e')\n",
            "Step    3\n",
            "  input: 52 ('e')\n",
            "  expected output: 1 (' ')\n",
            "Step    4\n",
            "  input: 1 (' ')\n",
            "  expected output: 28 ('F')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjdR6kIDAn2f",
        "colab_type": "code",
        "outputId": "3936f430-d1f5-49d2-b2b8-1313c3ebfef6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).padded_batch(BATCH_SIZE,padded_shapes=None, padding_values=None, drop_remainder=True)\n",
        "\n",
        "dataset"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PaddedBatchDataset shapes: ((128, 100), (128, 100)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EosBp_eMAqRy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Length of the vocabulary in chars\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzUR2R43Asj4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "  model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                              batch_input_shape=[batch_size, None]),\n",
        "    tf.keras.layers.GRU(rnn_units,\n",
        "                        return_sequences=True,\n",
        "                        stateful=True,\n",
        "                        recurrent_initializer='glorot_uniform'),\n",
        "    tf.keras.layers.Dense(vocab_size)\n",
        "  ])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ej-1P6kCAub1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = build_model(\n",
        "  vocab_size = len(vocab),\n",
        "  embedding_dim=embedding_dim,\n",
        "  rnn_units=rnn_units,\n",
        "  batch_size=BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DT6335uJAwLh",
        "colab_type": "code",
        "outputId": "0d669183-5ada-4877-9f88-ad132d0f2f18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "  example_batch_predictions = model(input_example_batch)\n",
        "  print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(128, 100, 75) # (batch_size, sequence_length, vocab_size)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXSVSFTjAzK0",
        "colab_type": "code",
        "outputId": "b6891686-e4d4-4c94-afd4-05903021ba35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (128, None, 256)          19200     \n",
            "_________________________________________________________________\n",
            "gru_3 (GRU)                  (128, None, 1024)         3938304   \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (128, None, 75)           76875     \n",
            "=================================================================\n",
            "Total params: 4,034,379\n",
            "Trainable params: 4,034,379\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxuLIUg2A1ZX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQTiFBpxA3CN",
        "colab_type": "code",
        "outputId": "e9fbb5aa-f15f-4090-ea4b-5b1841cf0963",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "sampled_indices"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([68, 54, 70, 19, 65, 60, 22, 25, 57, 14, 41,  2, 54, 40, 52, 29,  8,\n",
              "       74, 63,  6, 37, 26, 54, 21, 34, 62, 29, 43, 62, 38,  2, 74, 29, 23,\n",
              "       17,  3, 45, 33, 32, 14, 37, 30, 48, 69,  3, 69, 25,  4, 38, 26, 19,\n",
              "        6, 65,  0,  6, 67, 69,  6, 44, 58, 47, 55,  4, 20, 23, 70, 59, 33,\n",
              "       22, 26, 32, 54, 30, 59, 21, 13, 11, 16, 65, 66, 12, 57,  0, 36,  9,\n",
              "        9, 22, 71, 11,  4, 62, 41, 44, 46, 43, 24, 34, 30, 41, 67])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aw3oE7WZA4dz",
        "colab_type": "code",
        "outputId": "196db994-1ae9-4654-ab33-d58fc3fa09ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "print(\"Input: \\n\", repr(\"\".join(idx2char[input_example_batch[0]])))\n",
        "print()\n",
        "print(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char[sampled_indices ])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: \n",
            " 'the people stood afar off, and Moses drew near unto the\\nthick darkness where God was.\\n\\n20:22 And the'\n",
            "\n",
            "Next Char Predictions: \n",
            " \"ugw9rm?Cj4S!gReG-\\ufeffp*ODg;LoGUoP!\\ufeffGA7'WKJ4OHav'vC(PD9*r\\n*tv*VkZh(:AwlK?DJgHl;316rs2j\\nN..?x1(oSVYUBLHSt\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vyb8yMW_A6RM",
        "colab_type": "code",
        "outputId": "bd01db82-f9b8-4927-bd8e-df64f8c302ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "def loss(labels, logits):\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
        "\n",
        "example_batch_loss  = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction shape:  (128, 100, 75)  # (batch_size, sequence_length, vocab_size)\n",
            "scalar_loss:       4.3178225\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZDe-gl8A9LL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss=loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLmrEhsyA_n-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJvyxM0gBBtf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS=10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2B0uvkgBD8B",
        "colab_type": "code",
        "outputId": "53742bf6-f373-4f08-fdb9-bc879b8cd3f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "335/335 [==============================] - 43s 128ms/step - loss: 2.1014\n",
            "Epoch 2/10\n",
            "335/335 [==============================] - 44s 130ms/step - loss: 1.3492\n",
            "Epoch 3/10\n",
            "335/335 [==============================] - 44s 132ms/step - loss: 1.1821\n",
            "Epoch 4/10\n",
            "335/335 [==============================] - 44s 133ms/step - loss: 1.1125\n",
            "Epoch 5/10\n",
            "335/335 [==============================] - 44s 133ms/step - loss: 1.0714\n",
            "Epoch 6/10\n",
            "335/335 [==============================] - 44s 132ms/step - loss: 1.0417\n",
            "Epoch 7/10\n",
            "335/335 [==============================] - 44s 133ms/step - loss: 1.0173\n",
            "Epoch 8/10\n",
            "335/335 [==============================] - 44s 132ms/step - loss: 0.9973\n",
            "Epoch 9/10\n",
            "335/335 [==============================] - 44s 131ms/step - loss: 0.9790\n",
            "Epoch 10/10\n",
            "335/335 [==============================] - 44s 133ms/step - loss: 0.9629\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tz3mYjKjBFOc",
        "colab_type": "code",
        "outputId": "e86f522f-7d63-43d8-f99b-c08ec1035871",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.train.latest_checkpoint(checkpoint_dir)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./training_checkpoints/ckpt_10'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpnKnqelBlmm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
        "\n",
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "\n",
        "model.build(tf.TensorShape([1, None]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfjvoIf4Bndy",
        "colab_type": "code",
        "outputId": "2d538030-7fbd-475e-92b2-ee2e8b762f43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_5 (Embedding)      (1, None, 256)            19200     \n",
            "_________________________________________________________________\n",
            "gru_4 (GRU)                  (1, None, 1024)           3938304   \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (1, None, 75)             76875     \n",
            "=================================================================\n",
            "Total params: 4,034,379\n",
            "Trainable params: 4,034,379\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCyiP4wUBp1v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_text(model, start_string):\n",
        "  # Evaluation step (generating text using the learned model)\n",
        "\n",
        "  # Number of characters to generate\n",
        "  num_generate = 1000\n",
        "\n",
        "  # Converting our start string to numbers (vectorizing)\n",
        "  input_eval = [char2idx[s] for s in start_string]\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "  # Empty string to store our results\n",
        "  text_generated = []\n",
        "\n",
        "  # Low temperatures results in more predictable text.\n",
        "  # Higher temperatures results in more surprising text.\n",
        "  # Experiment to find the best setting.\n",
        "  temperature = 1.0\n",
        "\n",
        "  # Here batch size == 1\n",
        "  model.reset_states()\n",
        "  for i in range(num_generate):\n",
        "      predictions = model(input_eval)\n",
        "      # remove the batch dimension\n",
        "      predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "      # using a categorical distribution to predict the character returned by the model\n",
        "      predictions = predictions / temperature\n",
        "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "\n",
        "      # We pass the predicted character as the next input to the model\n",
        "      # along with the previous hidden state\n",
        "      input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "      text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "  return (start_string + ''.join(text_generated))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ktovv0RFhrkn",
        "outputId": "4f4f9838-23de-42f1-8a6d-67a224d90075",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "print(generate_text(model, start_string=u\"1:1\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1:166059028 THost the place wherefore the Lord hath present thee, that the fruit of their troubles are manifest the minded shall say they.\n",
            "\n",
            "1:19 And who art thornscording that I am ready also.\n",
            "\n",
            "1:8 Let not the LORD and the second priest shall pierce and ning of righteousness, and I shall rear\n",
            "unto thy brother's elect.\n",
            "\n",
            "11:15 Because the Son of man be good will keep your hearts?  6:16 I will make thee the pained as a bread of life, whereof the LORD can\n",
            "save upon Ethank of the children of\n",
            "Israel, saying, I hold them that have the spirit\n",
            "of things.\n",
            "\n",
            "7:20 And thine account me are taken from life, take heed to the people that\n",
            "from the dead I have very sorry when he is Christ's throne.\n",
            "\n",
            "11:2 For the tradition for A\n",
            "benct gain.\n",
            "\n",
            "11:16 Now it came to pass about this wifor, saying, Thus\n",
            "saith the LORD of hosts.\n",
            "\n",
            "4:17 And I have repared from the Father, and the power and brethren, abaril, in the law of men!\n",
            "from henceforth have joy about to be seen in himself, as an hendecr, neither have mercy on m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFhYQkIsCZqd",
        "colab_type": "text"
      },
      "source": [
        "# **Extra Functions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5uI8hFWCjJI",
        "colab_type": "code",
        "outputId": "ae6b1ff0-25f4-413f-8a10-386ccf6384dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.keras.Model.reset_states"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function tensorflow.python.keras.engine.network.Network.reset_states>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkMBWRQ2Bxk6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = build_model(\n",
        "  vocab_size = len(vocab),\n",
        "  embedding_dim=embedding_dim,\n",
        "  rnn_units=rnn_units,\n",
        "  batch_size=BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0RUVFSDCS7F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAxkcUj4CGkt",
        "colab_type": "code",
        "outputId": "b1bd5ab7-e464-46d9-ca8d-0ffbf8aade58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (64, None, 256)           16640     \n",
            "_________________________________________________________________\n",
            "gru_4 (GRU)                  (64, None, 1024)          3938304   \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (64, None, 65)            66625     \n",
            "=================================================================\n",
            "Total params: 4,021,569\n",
            "Trainable params: 4,021,569\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1o4Yt-EzCI25",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(inp, target):\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions = model(inp)\n",
        "    loss = tf.reduce_mean(\n",
        "        tf.keras.losses.sparse_categorical_crossentropy(\n",
        "            target, predictions, from_logits=True))\n",
        "  grads = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "  return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQKsQhPRCM_y",
        "colab_type": "code",
        "outputId": "060ac850-5d5b-4392-aef5-02c2836d360d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Training step\n",
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  # initializing the hidden state at the start of every epoch\n",
        "  # initally hidden is None\n",
        "  hidden = model.reset_states()\n",
        "\n",
        "  for (batch_n, (inp, target)) in enumerate(dataset):\n",
        "    loss = train_step(inp, target)\n",
        "\n",
        "    if batch_n % 100 == 0:\n",
        "      template = 'Epoch {} Batch {} Loss {}'\n",
        "      print(template.format(epoch+1, batch_n, loss))\n",
        "\n",
        "  # saving (checkpoint) the model every 5 epochs\n",
        "  if (epoch + 1) % 5 == 0:\n",
        "    model.save_weights(checkpoint_prefix.format(epoch=epoch))\n",
        "\n",
        "  print ('Epoch {} Loss {:.4f}'.format(epoch+1, loss))\n",
        "  print ('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n",
        "\n",
        "model.save_weights(checkpoint_prefix.format(epoch=epoch))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.embeddings\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.recurrent_kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.embeddings\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.recurrent_kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.bias\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
            "Epoch 1 Batch 0 Loss 4.173309803009033\n",
            "Epoch 1 Batch 100 Loss 2.347487449645996\n",
            "Epoch 1 Loss 2.1414\n",
            "Time taken for 1 epoch 12.885401964187622 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 2.1676666736602783\n",
            "Epoch 2 Batch 100 Loss 1.9348502159118652\n",
            "Epoch 2 Loss 1.8182\n",
            "Time taken for 1 epoch 11.865055561065674 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 1.7781000137329102\n",
            "Epoch 3 Batch 100 Loss 1.6764963865280151\n",
            "Epoch 3 Loss 1.5959\n",
            "Time taken for 1 epoch 12.137167692184448 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 1.5909942388534546\n",
            "Epoch 4 Batch 100 Loss 1.4862899780273438\n",
            "Epoch 4 Loss 1.5410\n",
            "Time taken for 1 epoch 11.986477613449097 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 1.4566761255264282\n",
            "Epoch 5 Batch 100 Loss 1.4397575855255127\n",
            "Epoch 5 Loss 1.4653\n",
            "Time taken for 1 epoch 12.101974725723267 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 1.4007296562194824\n",
            "Epoch 6 Batch 100 Loss 1.3805246353149414\n",
            "Epoch 6 Loss 1.3879\n",
            "Time taken for 1 epoch 12.189754724502563 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 1.3064182996749878\n",
            "Epoch 7 Batch 100 Loss 1.311234474182129\n",
            "Epoch 7 Loss 1.3675\n",
            "Time taken for 1 epoch 12.2195725440979 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 1.2441411018371582\n",
            "Epoch 8 Batch 100 Loss 1.3045529127120972\n",
            "Epoch 8 Loss 1.2887\n",
            "Time taken for 1 epoch 12.268964767456055 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 1.2450652122497559\n",
            "Epoch 9 Batch 100 Loss 1.2689166069030762\n",
            "Epoch 9 Loss 1.2676\n",
            "Time taken for 1 epoch 12.254668712615967 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 1.2012780904769897\n",
            "Epoch 10 Batch 100 Loss 1.2501813173294067\n",
            "Epoch 10 Loss 1.2461\n",
            "Time taken for 1 epoch 12.305797576904297 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9u5UVWMPqPm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from prepare_data2 import parse_seq\n",
        "import pickle\n",
        "os.chdir('/content/drive/My Drive/Colab Notebooks/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKuiYYxUCPCL",
        "colab_type": "code",
        "outputId": "c6703f30-27a9-4d89-d488-dd21f3024f07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "path_to_file = '/content/drive/My Drive/Colab Notebooks/the-king-james-bible.txt.tfrecords'\n",
        "raw_dataset = tf.data.TFRecordDataset(path_to_file)\n",
        "for raw_record in raw_dataset.take(10):\n",
        "  print(repr(raw_record))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tf.Tensor: shape=(), dtype=string, numpy=b\"\\n:\\n8\\n\\x03seq\\x121\\x1a/\\n-\\x01\\x1e=\\x0b5&;,@95\\x1b<<\\x035<\\x055\\x14<@\\x0b@055'\\n##\\x0b\\x045H\\x0b\\x0c\\x0b@;@EEE\\x02\">\n",
            "<tf.Tensor: shape=(), dtype=string, numpy=b'\\nH\\nF\\n\\x03seq\\x12?\\x1a=\\n;\\x0158\\x0c59=\\x0b5 \\x0bC;\\x0c\\x0c;\\x0cC5H<\\x0454,\\x0b\\n9\\x0b\\x0459=\\x0b5=\\x0b\\nA\\x0b\\x0c5\\n\\x0c\\x0459=\\x0b5\\x0b\\n,9=$EE\\x02'>\n",
            "<tf.Tensor: shape=(), dtype=string, numpy=b'\\n\\xa4\\x01\\n\\xa1\\x01\\n\\x03seq\\x12\\x99\\x01\\x1a\\x96\\x01\\n\\x93\\x01\\x015\\x12\\x0c\\x0459=\\x0b5\\x0b\\n,9=5\\x06\\n@5\\x06;9=<K95\\x05<,%J5\\n\\x0c\\x045A<;\\x04\"5\\n\\x0c\\x045\\x04\\n,\\x03\\x0c\\x0b@@5\\x06\\n@5K.<\\x0cE9=\\x0b5\\x05\\n4\\x0b5<\\x0559=\\x0b5\\x04\\x0b\\x0b.$5\\x12\\x0c\\x0459=\\x0b5\\x1f.;,;95<\\x055H<\\x045%<A\\x0b\\x045K.<\\x0c59=\\x0b5\\x05\\n4\\x0b5<\\x0559=\\x0bE\\x06\\n9\\x0b,@$EE\\x02'>\n",
            "<tf.Tensor: shape=(), dtype=string, numpy=b'\\nH\\nF\\n\\x03seq\\x12?\\x1a=\\n;\\x015\\x12\\x0c\\x045H<\\x045@\\n;\\x04J5\\x08\\x0b959=\\x0b,\\x0b5 \\x0b5#;C=905\\n\\x0c\\x0459=\\x0b,\\x0b5\\x06\\n@5#;C=9$EE\\x02'>\n",
            "<tf.Tensor: shape=(), dtype=string, numpy=b'\\ng\\ne\\n\\x03seq\\x12^\\x1a\\\\\\nZ\\x015\\x12\\x0c\\x045H<\\x045@\\n\\x0659=\\x0b5#;C=9J59=\\n95;95\\x06\\n@5C<<\\x0405\\n\\x0c\\x045H<\\x045\\x04;A;\\x04\\x0b\\x0459=\\x0b5#;C=9E\\x05,<%59=\\x0b5\\x04\\n,\\x03\\x0c\\x0b@@$EE\\x02'>\n",
            "<tf.Tensor: shape=(), dtype=string, numpy=b'\\n\\x86\\x01\\n\\x83\\x01\\n\\x03seq\\x12|\\x1az\\nx\\x015\\x12\\x0c\\x045H<\\x0454\\n##\\x0b\\x0459=\\x0b5#;C=952\\n\\x11J5\\n\\x0c\\x0459=\\x0b5\\x04\\n,\\x03\\x0c\\x0b@@5=\\x0b54\\n##\\x0b\\x045D;C=9$E\\x12\\x0c\\x0459=\\x0b5\\x0bA\\x0b\\x0c;\\x0cC5\\n\\x0c\\x0459=\\x0b5%<,\\x0c;\\x0cC5\\x06\\x0b,\\x0b59=\\x0b5\\x05;,@95\\x04\\n\\x11$EE\\x02'>\n",
            "<tf.Tensor: shape=(), dtype=string, numpy=b'\\n\\x83\\x01\\n\\x80\\x01\\n\\x03seq\\x12y\\x1aw\\nu\\x015\\x12\\x0c\\x045H<\\x045@\\n;\\x04J5\\x08\\x0b959=\\x0b,\\x0b5 \\x0b5\\n5\\x05;,%\\n%\\x0b\\x0c95;\\x0c59=\\x0b5%;\\x04@95<\\x0559=\\x0b5\\x06\\n9\\x0b,@JE\\n\\x0c\\x045#\\x0b95;95\\x04;A;\\x04\\x0b59=\\x0b5\\x06\\n9\\x0b,@5\\x05,<%59=\\x0b5\\x06\\n9\\x0b,@$EE\\x02'>\n",
            "<tf.Tensor: shape=(), dtype=string, numpy=b'\\n\\xa6\\x01\\n\\xa3\\x01\\n\\x03seq\\x12\\x9b\\x01\\x1a\\x98\\x01\\n\\x95\\x01\\x015\\x12\\x0c\\x045H<\\x045%\\n\\x04\\x0b59=\\x0b5\\x05;,%\\n%\\x0b\\x0c9J5\\n\\x0c\\x045\\x04;A;\\x04\\x0b\\x0459=\\x0b5\\x06\\n9\\x0b,@5\\x06=;4=5\\x06\\x0b,\\x0bEK\\x0c\\x04\\x0b,59=\\x0b5\\x05;,%\\n%\\x0b\\x0c95\\x05,<%59=\\x0b5\\x06\\n9\\x0b,@5\\x06=;4=5\\x06\\x0b,\\x0b5\\n <A\\x0b59=\\x0b5\\x05;,%\\n%\\x0b\\x0c90E\\n\\x0c\\x045;95\\x06\\n@5@<$EE\\x02'>\n",
            "<tf.Tensor: shape=(), dtype=string, numpy=b'\\nk\\ni\\n\\x03seq\\x12b\\x1a`\\n^\\x015\\x12\\x0c\\x045H<\\x0454\\n##\\x0b\\x0459=\\x0b5\\x05;,%\\n%\\x0b\\x0c95\\x17\\x0b\\nA\\x0b\\x0c$5\\x12\\x0c\\x0459=\\x0b5\\x0bA\\x0b\\x0c;\\x0cC5\\n\\x0c\\x0459=\\x0bE%<,\\x0c;\\x0cC5\\x06\\x0b,\\x0b59=\\x0b5@\\x0b4<\\x0c\\x045\\x04\\n\\x11$EE\\x02'>\n",
            "<tf.Tensor: shape=(), dtype=string, numpy=b'\\n\\x94\\x01\\n\\x91\\x01\\n\\x03seq\\x12\\x89\\x01\\x1a\\x86\\x01\\n\\x83\\x01\\x015\\x12\\x0c\\x045H<\\x045@\\n;\\x04J5\\x08\\x0b959=\\x0b5\\x06\\n9\\x0b,@5K\\x0c\\x04\\x0b,59=\\x0b5=\\x0b\\nA\\x0b\\x0c5 \\x0b5C\\n9=\\x0b,\\x0b\\x0459<C\\x0b9=\\x0b,EK\\x0c9<5<\\x0c\\x0b5.#\\n4\\x0bJ5\\n\\x0c\\x045#\\x0b959=\\x0b5\\x04,\\x115#\\n\\x0c\\x045\\n..\\x0b\\n,05\\n\\x0c\\x045;95\\x06\\n@5@<$EE\\x02'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mdLtfp1QW8z",
        "colab_type": "code",
        "outputId": "fd80b850-d62d-4d41-ff43-97a95e4a3ec6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        }
      },
      "source": [
        "#sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "sequences = data.padded_batch(seq_length+1, padded_shapes=None, padding_values=None, drop_remainder=True)\n",
        "\n",
        "for item in sequences.take(5):\n",
        "  print(repr(''.join(idx2char[item.numpy()])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mexecution_mode\u001b[0;34m(mode)\u001b[0m\n\u001b[1;32m   1985\u001b[0m       \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecutor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecutor_new\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1986\u001b[0;31m       \u001b[0;32myield\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1987\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    654\u001b[0m             \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m             output_shapes=self._flat_output_shapes)\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   2362\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6652\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6653\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6654\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
            "\u001b[0;31mNotFoundError\u001b[0m: \n:\n8\n\u0003seq\u00121\u001a/\n-\u0001\u001e=\u000b5&;,@95\u001b<<\u00035<\u00055\u0014<@\u000b@055'\n##\u000b\u00045H\u000b\f\u000b@;@EEE\u0002; No such file or directory [Op:IteratorGetNext]",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-39e9de3b02a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadded_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_length\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadded_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_remainder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msequences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx2char\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# For Python 3 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    668\u001b[0m     \u001b[0;34m\"\"\"Returns a nested structure of `Tensor`s containing the next element.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    659\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_compatible_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 661\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_compatible_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     97\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0;31m# Suppress StopIteration *unless* it's the same exception that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mexecution_mode\u001b[0;34m(mode)\u001b[0m\n\u001b[1;32m   1987\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1988\u001b[0m       \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecutor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecutor_old\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1989\u001b[0;31m       \u001b[0mexecutor_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1990\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/executor.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     65\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;34m\"\"\"Waits for ops dispatched in this executor to finish.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0mpywrap_tfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFE_ExecutorWaitForAllPendingNodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mclear_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFoundError\u001b[0m: \n:\n8\n\u0003seq\u00121\u001a/\n-\u0001\u001e=\u000b5&;,@95\u001b<<\u00035<\u00055\u0014<@\u000b@055'\n##\u000b\u00045H\u000b\f\u000b@;@EEE\u0002; No such file or directory"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLQ5dF6HRARa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
